<!DOCTYPE html>
<!--
  Template Name: Oleald
  Author: <a href="https://www.os-templates.com/">OS Templates</a>
  Author URI: https://www.os-templates.com/
  Licence: Free to use under our free template licence terms
  Licence URI: https://www.os-templates.com/template-terms
  -->
<html lang="">
<!-- To declare your language - read more here: https://www.w3.org/International/questions/qa-html-language-declarations -->

<head>
  <title>Challenge at CVPR 2023 Autonomous Driving Workshop</title>
  <link rel="icon" 
      type="image/png" 
      href="images/team_logo.png">
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no">
  <link href="layout/styles/layout.css" rel="stylesheet" type="text/css" media="all">
  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script>
    MathJax = {
      tex: {
        inlineMath: [['$', '$'], ['\\(', '\\)']]
      }
    };
  </script>
  <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js">
  </script>

  <style>
    img:hover {
      opacity: 0.3;
    }
  </style>

</head>

<body id="top">
  <!-- ################################################################################################ -->
  <!-- ################################################################################################ -->
  <!-- ################################################################################################ -->
  <!-- Top Background Image Wrapper -->
  <div class="bgded overlay " style="background-image:url('./images/challenge/poster.png');">
    <!-- ################################################################################################ -->

    <!-- ################################################################################################ -->
    <!-- ################################################################################################ -->
    <!-- ################################################################################################ -->
    <div class="wrapper row1">

      <!-- ################################################################################################ -->
      <!-- ################################################################################################ -->
      <!-- ################################################################################################ -->
      <div id="pageintro" class="hoc clear">
        <!-- ################################################################################################ -->
        <article>
          <!-- <br><br>
          <br><br>
          <br><br><br><br> -->


          <h1><b class="logo-name" style="font-size: 3em">
            Autonomous Driving Challenge
          </b></h1>


          <!-- <h3 class="heading" style="font-size: 3.5em">OpenLane Mapping Challenge</h3> -->
          <!-- <h2 style="font-size: 1.8em">CVPR 2023</h2> -->
          <footer>
            <b style="font-size: 1.5em">In conjunction with</b>
            <br><br>
            <b style="font-size: 2em">CVPR 2023 Workshops</b>
            <br><br>
            <div style="padding:0 60px;line-height: 1.7;">
            <li><b><a href="https://opendrivelab.com/e2ead/cvpr23" style="font-size: 1.5em"> End-to-End Autonomous Driving Workshop</a></b></li>
            <li><b><a href="https://www.vcad.site/" style="font-size: 1.5em">Vision-Centric Autonomous Driving Workshop</a></b></li>
            </div>
            <br>
            <b style="font-size: 1.5em">June 18-19, Vancouver, Canada</b>
 
          </footer>
        </article>
        <!-- ################################################################################################ -->
      </div>
    </div>
  </div>

  <!-- ################################################################################################ -->

  <!-- End Top Background Image Wrapper -->


  <!-- ################################################################################################ -->
  <!-- ################################################################################################ -->
  <div class="wrapper row3">
    <main class="hoc container clear">
      <!-- main body -->
      <!-- ################################################################################################ -->
      <div class="sidebar one_quarter first">
        <!-- ################################################################################################ -->
        <h6> <b></b></h6>

        <nav class="sdb_holder" style="display:inline-block; position:fixed;bottom:1000px; left:40px;">
          <ul>
            <li><a href="#Overview" style="font-size: 1.2em; line-height: 1.2; ">- Overview</a></li>
          </ul>
          <ul>
            <li><a href="#Track1" style="font-size: 1.2em; line-height: 1.2;">- OpenLane Topology </a></li>
          </ul>
          <ul>
            <li><a href="#Track2" style="font-size: 1.2em; line-height: 1.2;">- Occupancy Prediction </a></li>
          </ul>
          <ul>
            <li><a href="#Track3" style="font-size: 1.2em; line-height: 1.2;">- nuPlan Planning</a></li>
          </ul>

          <ul>
            <li><a href="#rules" style="font-size: 1.2em; line-height: 1.2;">- General Rules</a></li>
          </ul>
          
        </nav>


        <!-- ################################################################################################ -->
      </div>
      <div class="content three_quarter">
        <!-- ################################################################################################ -->




        <!-- Overview -->

        <h3><b class="btb" target="_blank" id="Overview" style="font-size: 2.5em;">
          Overview
        </b></h3>

        <br>

        <h4><b>Why these Challenges?</b></h4>

        <p>
           Autonomous driving is developing fast. 
           Although still deemed important, the requirement for cutting-edge algorithms is no longer to achieve as high as mAP for object detectors, or to recognize lanes as conventional segmentation. 
           We believe the <topic>future</topic> of autonomous driving algorithms is to <code>bond perception closely with planning</code>. 
           The goal of each module (object detection, lane line recognition, etc.) in perception is to serve for better planning. 
           As such, we introduce three <topic>curated, brand-new</topic> challenges following such a philosophy.
        </p>

        <li style="list-style-type:disc"> 
          <topic>OpenLane Topology Challenge</topic>. 
          Go beyond conventional lane line detection as segmentation. 
          Recognizing lanes as an abstraction of the scene - <code>centerline</code>, and building the topology between lanes and traffic elements. 
          Such a topology is to facilitate planning and routing.
        </li>

        <br>

        <li style="list-style-type:disc"> 
          <topic>Occupancy Prediction Challenge</topic>. 
          The representation of 3D bounding boxes is not enough to describe general objects (obstacles) in daily scenarios.
          <!-- for autonomous driving.  -->
          Instead, inspired by the concept in Robotics, we deem general object detection as an <code>Occupancy</code> representation to cover more irregularly shaped objects (e.g., protruding).
          The output could also be fed as cost volume for planning. 
          This idea is also endorsed by <a href="https://www.mobileye.com/ces-2023">Mobileye at CES 2023</a> and <a href="https://www.youtube.com/watch?v=ODSJsviD_SU">Tesla AI Day 2022</a>.
        </li>

        <br>

        <li style="list-style-type:disc"> 
          <topic>nuPlan Planning Challenge</topic>. 
          To verify the effectiveness of the previous two newly-designed modules in perception, we need an ultimate planning framework with a 
          <code>closed-loop</code> setting, trained <code>end-to-end</code>.
          Previous motion planning benchmarks focus on short-term motion forecasting and are limited to open-loop evaluation. 
          <code>nuPlan</code> introduces long-term planning of the ego vehicle and corresponding metrics.
        </li>


        <br>
        <figure>
          <img alt="motivation" src="images/challenge/overview_t.png" style="pointer-events: none;"/>
          <figcaption>Motivation of the Challenges: bond perception more closely with planning.</figcaption>
        </figure>
        <br><br>



        <!-- contact -->

        <h4><b>Contact</b></h4>

        <a href="https://join.slack.com/t/opendrivelab/shared_invite/zt-1p2by4kxs-Nulw9MsDEGEpsjo6fG2osg">
          <img
            src="https://img.shields.io/badge/Slack-Join-important?logo=slack&amp"
            alt="Join Slack" style="height: 25px"
          />
        </a>
        Join Slack to Chat with Challenge organizers. Please follow the guidelines in <code>#general</code> and join the track-specific channels.

        <br>

        <a href="mailto:workshop-e2e-ad@googlegroups.com">
          <img
            src="https://img.shields.io/badge/email-Send-important?logo=gmail&amp"
            alt="Send E-mail" style="height: 25px"
          />
        </a>
        Contact us via <code>workshop-e2e-ad@googlegroups.com</code>.
        
        <br><br><br>



        <!-- host -->

        <h4><b>Host</b></h4>

        <p>
          The year 2023's edition of the Challenge is hosted by:
        </p>

        <br>

        <div class="grid">
          <div class="grid-item" style="min-width: 220px; max-width: 220px; padding-left: 1rem; padding-right: 1.5rem;" >
            <li class="speakers-item ">
              <span class="speaker-photo">
                <a href="https://opendrivelab.com" target="_blank">
                  <img class="photo" style="width: 220px; border-radius:100%; overflow:hidden;"
                    src="images/challenge/shanghaiailab_w.png" >
                  <p class="speakers-name" style="text-align:center;font-size: 0.9em;"><b>OpenDriveLab <br> at Shanghai AI Lab</b>
                  </p>
                </a>
              </span>
            </li>
          </div>
          <div class="grid-item" style="min-width: 220px; max-width: 220px; padding-left: 1rem; padding-right: 1.5rem;" >
            <li class="speakers-item " >
              <span class="speaker-photo">
                <a href="http://group.iiis.tsinghua.edu.cn/~marslab/#" target="_blank">
                  <img class="photo" style="width: 220px; border-radius:100%; overflow:hidden;"
                    src="images/challenge/mars_w.png" > 

                  <p class="speakers-name" style="text-align:center;font-size: 0.9em;"> <b>MARS Lab <br> at Tsinghua University</b> </p>
                </a>
              </span>
            </li>
          </div>
          <div class="grid-item" style="min-width: 220px; max-width: 220px; padding-left: 1rem; padding-right: 1.5rem;" >
            <li class="speakers-item " >
              <span class="speaker-photo">
                <a href="https://motional.com/" target="_blank">
                  <img class="photo" style="width: 220px; border-radius:100%; overflow:hidden;"
                    src="images/challenge/motion_w.jpg"  > 

                  <p class="speakers-name" style="text-align:center;font-size: 0.9em;"> <b>nuPlan team <br>  from Motional</b> </p>
                </a>
              </span>
            </li>
          </div>
        </div>



        <br><br>
        <hr>
        <br><br><br>



        <!-- track 1 -->

        <h3><b class="btb" target="_blank" id="Track1" style="font-size: 2.5em;">
          Track 1: OpenLane Topology
        </b></h3>
        
        <p style="line-height:30px;">

        <a href="https://github.com/OpenDriveLab/OpenLane-V2">
          <img
            src="https://img.shields.io/badge/website-GitHub-blueviolet"
            alt="GitHub" style="height: 25px"
            onmousemove="this.className='yellow'"
          />
        </a>

        <a href="https://github.com/OpenDriveLab/OpenLane-V2">
          <img
            src="https://img.shields.io/github/stars/OpenDriveLab/OpenLane-V2?style=social"
            alt="GitHub" style="height: 25px"
            onmousemove="this.className='yellow'"
          />
        </a>

        <a href="https://github.com/OpenDriveLab/OpenLane-V2">
          <img
            src="https://img.shields.io/github/forks/OpenDriveLab/OpenLane-V2?style=social"
            alt="GitHub" style="height: 25px"
            onmousemove="this.className='yellow'"
          />
        </a>

        <a href="https://eval.ai/web/challenges/challenge-page/1925">
          <img
            src="https://img.shields.io/badge/submission-EvalAI-blueviolet"
            alt="EvalAI" style="height: 25px"
          />
        </a>
      </p>

        <br><br>

        <h4><b>Task Description</b></h4>
        <p>
          The novel <a href="https://github.com/OpenDriveLab/OpenLane-V2">OpenLane-V2</a> dataset is the perception and reasoning benchmark for scene structure in autonomous driving. 
          Given multi-view images covering the whole panoramic field of view, 
          participants are required to deliver not only perception results of lanes and traffic elements but also topology relationships among lanes and between lanes and traffic elements simultaneously.
          <br>
          For those interested in HD map construction, we also provide a <a href='#side-track'>side track</a>, <code>HD Map construction track</code>.
          We use <code>the same metric</code> to evaluate the performances of lane line detection as 3D Lane Detection task of OpenLane topology track.
        </p>


        <br>


        <h4><b>Participation</b></h4>
        <p>
          The primary metric is <a href="https://github.com/OpenDriveLab/OpenLane-V2#task">OpenLane-V2 Score (OLS)</a>, which comprises evaluations on three sub-tasks.
          On the website, we provide tools for 
          <a href="https://github.com/OpenDriveLab/OpenLane-V2/blob/master/docs/devkit.md#openlanev2dataset">data access</a>,
          <a href="https://github.com/OpenDriveLab/OpenLane-V2#plugin">training models</a>,
          <a href="https://github.com/OpenDriveLab/OpenLane-V2/blob/master/docs/devkit.md#openlanev2evaluation">evaluations</a>,
          and <a href="https://github.com/OpenDriveLab/OpenLane-V2/blob/master/docs/devkit.md#openlanev2visualization">visualization</a>.
          To submit your results on <a href="https://eval.ai/web/challenges/challenge-page/1925/overview">EvalAI</a>, please 
          follow the <a href="https://github.com/OpenDriveLab/OpenLane-V2/blob/master/docs/submission.md#submission">submission instructions</a>.
          The leaderboard would be maintained <a href="https://github.com/OpenDriveLab/OpenLane-V2#benchmark-and-leaderboard-to-be-released">here</a>.
        </p>


        <br>


        <h4><b>Important dates</b></h4>
        <p>
          <table style="width: 50%;">
            <tbody>
              <tr style="background-color: white">
                <td>Challenge Period Open</td><td>Mar 16, 2023</td>
              </tr>
              <tr style="background-color: white">
                <td>Challenge Period End</td><td>May 27, 2023</td>
              </tr>
              <tr style="background-color: white">
                <td>Finalist Notification</td><td>May 29, 2023</td>
              </tr>
              <tr style="background-color: white">
                <td>Technical Report Deadline</td><td>Jun 10, 2023</td>
              </tr>
              <tr style="background-color: white">
                <td>Winner Announcement</td><td>Jun 12, 2023</td>
              </tr>
            </tbody>
          </table>
          <footer ><i style ="font-size: 0.8em;">* &nbsp; All due at 00:00 UTC+8.</i></b>
          <footer ><i style ="font-size: 0.8em;">** The test server will remain open after the challenge.</i></b>
        </p>


        <br>

        
        <h4><b> Award</b></h4>
        <p>
          For verified finalists participating in <code>OpenLane topology track</code>, teams with the first, second, and third highest scores will be awarded.
          Besides, the team with the most innovative method will be awarded.
          The prizes will be announced.
        </p>
        

        <br>


        <h4><b>Contact</b></h4>
        <p>
          <li style="list-style-type:disc">
            Yang Li, <code>liyang@opendrivelab.com</code>
          </li>
          <li style="list-style-type:disc">
            Slack channel: <code>#openlane-challenge-2023</code>
          </li>
        </p>


        <br>


        <h4 ><b id='side-track'> Side Track: Online HD Map Construction</b></h4>
        <p style="line-height:30px;">

          <a href="https://github.com/Tsinghua-MARS-Lab/Online-HD-Map-Construction-CVPR2023">
            <img
              src="https://img.shields.io/badge/website-GitHub-blueviolet"
              alt="GitHub" style="height: 25px"
              onmousemove="this.className='yellow'"
            />
          </a>
  
          <!-- <a href="https://github.com/Tsinghua-MARS-Lab/Online-HD-Map-Construction-CVPR2023">
            <img
              src="https://img.shields.io/github/stars/OpenDriveLab/OpenLane-V2?style=social"
              alt="GitHub" style="height: 25px"
              onmousemove="this.className='yellow'"
            />
          </a> -->
  
          <!-- <a href="https://github.com/OpenDriveLab/OpenLane-V2">
            <img
              src="https://img.shields.io/github/forks/OpenDriveLab/OpenLane-V2?style=social"
              alt="GitHub" style="height: 25px"
              onmousemove="this.className='yellow'"
            />
          </a> -->
  
          <a href="https://eval.ai/web/challenges/challenge-page/1954/overview">
            <img
              src="https://img.shields.io/badge/submission-EvalAI-blueviolet"
              alt="EvalAI" style="height: 25px"
            />
          </a>
        </p>
        <p>
            Online HD map construction task aims to dynamically construct the local semantic map based on onboard sensor observations. Compared to lane detection, our constructed HD map provides more semantics information of multiple categories.
            Please refer to the pages of <a href="https://github.com/Tsinghua-MARS-Lab/Online-HD-Map-Construction-CVPR2023">repository</a> 
          and <a href="https://eval.ai/web/challenges/challenge-page/1954/overview">submission</a> for more details.
     
      
  
          <!-- Please refer to the pages of <a href="https://github.com/Tsinghua-MARS-Lab/Online-HD-Map-Construction-CVPR2023">repository</a> 
          and <a href="https://eval.ai/web/challenges/challenge-page/1954/overview">submission</a> for more details. -->
        </p>


        <br>


        <h4><b>Related Literature</b></h4>
        <p>
          <li style="list-style-type:disc; font-size: 0.8em;">
            <a href="https://arxiv.org/pdf/2010.04159.pdf">
              Deformable DETR: Deformable Transformers for End-to-End Object Detection
            </a>
          </li>
          <li style="list-style-type:disc; font-size: 0.8em;">
            <a href="https://openaccess.thecvf.com/content/ICCV2021/papers/Can_Structured_Birds-Eye-View_Traffic_Scene_Understanding_From_Onboard_Images_ICCV_2021_paper.pdf">
              Structured Bird's-Eye-View Traffic Scene Understanding From Onboard Images
            </a>
          </li>
          <li style="list-style-type:disc; font-size: 0.8em;">
            <a href="https://arxiv.org/pdf/2206.08920.pdf">
              VectorMapNet: End-to-end Vectorized HD Map Learning
            </a>
          </li>
          <li style="list-style-type:disc; font-size: 0.8em;">
            <a href="https://arxiv.org/pdf/2208.14437.pdf">
              MapTR: Structured Modeling and Learning for Online Vectorized HD Map Construction
            </a>
          </li>
        </p>



        <br><br><br>
        <hr>
        <br><br><br>



        <!-- track 2 -->

        <h3><b class="btb" target="_blank" id="Track2" style="font-size: 2.5em;">
          Track 2: Occupancy Prediction
        </b></h3>

        <a href="">
          <img
            src="https://img.shields.io/badge/website-todo-brightgreen"
            alt="todo" style="height: 25px"
          />
        </a>

        <a href="https://eval.ai/web/challenges/challenge-page/1956/overview">
          <img
            src="https://img.shields.io/badge/submission-EvalAI-brightgreen"
            alt="EvalAI" style="height: 25px"
          />
        </a>


        <br><br><br>


        <h4><b>Task Description</b></h4>
        <p>
          Unlike previous perception representations, which depend on predefined geometric primitives or perceived data modalities, 
          occupancy enjoys the flexibility to describe entities in arbitrary shapes.
          In this track, we provide a large-scale occupancy <code>benchmark</code>. 
          Given multi-view images covering the whole panoramic field of view, 
          participants are needed to provide the occupancy state and semantics of each voxel in 3D space for the complete scene.
        </p>


        <br>


        <h4><b>Participation</b></h4>
        <p>
          <code>todo</code>
        </p>


        <br>


        <h4><b>Important dates</b></h4>
        <code>to check</code>
        <p>
          <table style="width: 50%;">
            <tbody>
              <tr style="background-color: white">
                <td>Challenge Period Open</td><td>Mar 16, 2023</td>
              </tr>
              <tr style="background-color: white">
                <td>Challenge Period End</td><td>May 27, 2023</td>
              </tr>
              <tr style="background-color: white">
                <td>Finalist Notification</td><td>May 29, 2023</td>
              </tr>
              <tr style="background-color: white">
                <td>Technical Report Deadline</td><td>Jun 10, 2023</td>
              </tr>
              <tr style="background-color: white">
                <td>Winner Announcement</td><td>Jun 12, 2023</td>
              </tr>
            </tbody>
          </table>
          <footer ><i style ="font-size: 0.8em;">* &nbsp; All due at 00:00 UTC+8.</i></b>
          <footer ><i style ="font-size: 0.8em;">** The test server will remain open after the challenge.</i></b>
        </p>


        <br>

        
        <h4><b> Award</b></h4>
        <p>
          <code>to check</code>
          For verified finalists, teams with the first, second, and third highest scores will be awarded.
          Besides, the team with the most innovative method will be awarded.
          The prizes will be announced.
        </p>


        <br>


        <h4><b>Contact</b></h4>
        <p>
          <li style="list-style-type:disc">
            <code>todo</code>
          </li>
          <li style="list-style-type:disc">
            Slack channel: <code>#occupancy-challenge-2023</code>
          </li>
        </p>

        <br>


        <h4><b>Related Literature</b></h4>
        <p>
          <li style="list-style-type:disc; font-size: 0.8em;">
            <a href="https://arxiv.org/pdf/2003.04618.pdf">
              Convolutional Occupancy Networks
            </a>
          </li>
          <li style="list-style-type:disc; font-size: 0.8em;">
            <a href="https://openaccess.thecvf.com/content/CVPR2022/papers/Cao_MonoScene_Monocular_3D_Semantic_Scene_Completion_CVPR_2022_paper.pdf">
              MonoScene: Monocular 3D Semantic Scene Completion
            </a>
          </li>
          <li style="list-style-type:disc; font-size: 0.8em;">
            <a href="https://arxiv.org/pdf/2301.00527.pdf">
              Diffusion Probabilistic Models for Scene-Scale 3D Categorical Data
            </a>
          </li>
        </p>



        <!-- <div class="scrollable">
          <table>
            <thead>
              <tr>
                <th>Method</th>
                <th>OLS (main metric)</th>
                <th> $mAP_{LC}$</th>
                <th> $mAP_{TE}$</th>
                <th> $mAP_{LCLC}$ </th>
                <th> $mAP_{LCTE}$</th>
                <th> F-Score</th>

              </tr>
            </thead>
            <tbody>
              <tr>
                <td><a href="#">\</a></td>
                <td>\</td>
                <td>\</td>
                <td>\</td>
                <td>\</td>
                <td>\</td>
                <td>\</td>
              </tr>
              <tr>
                <td>\</td>
                <td>\</td>
                <td>\</td>
                <td><a href="#">\</a></td>
                <td>\</td>
                <td>\</td>
                <td>\</td>
              </tr>
              <tr>
                <td><a href="#">\</a></td>
                <td>\</td>
                <td>\</td>
                <td>\</td>
                <td>\</td>
                <td>\</td>
                <td>\</td>
              </tr>
              <tr>
                <td><a href="#">\</a></td>
                <td>\</td>
                <td>\</td>
                <td>\</td>
                <td>\</td>
                <td>\</td>
                <td>\</td>
              </tr>
            </tbody>
          </table>
        </div> -->



        <br><br><br>
        <hr>
        <br><br><br>



        <!-- track 3 -->

        <h3><b class="btb" target="_blank" id="Track3" style="font-size: 2.5em;">
          Track 3: nuPlan Planning
        </b></h3>

        <a href="https://nuplan-devkit.readthedocs.io/en/latest/competition.html">
          <img
            src="https://img.shields.io/badge/website-Competition-blue"
            alt="Competition" style="height: 25px"
          />
        </a>

        <a href="https://eval.ai/web/challenges/challenge-page/1856/overview">
          <img
            src="https://img.shields.io/badge/submission-EvalAI-blue"
            alt="EvalAI" style="height: 25px"
          />
        </a>


        <br><br><br>


        <h4><b>Task Description</b></h4>
        <p>
          <code>todo dataset / input / output</code>
          Previous benchmarks focus on short-term motion forecasting and are limited to open-loop evaluation.
          NuPlan introduces long-term planning of the ego vehicle and corresponding metrics.
          Provided as docker containers, submissions are deployed for simulation and evaluation.
        </p>


        <br>


        <h4><b>Participation</b></h4>
        <p>
          <code>todo</code>
        </p>


        <br>


        <h4><b>Important dates</b></h4>
        <code>to check</code>
        <p>
          <table style="width: 50%;">
            <tbody>
              <tr style="background-color: white">
                <td>Test Phase Start</td><td>Jan 30, 2023</td>
              </tr>
              <tr style="background-color: white">
                <td>Test Phase End</td><td>May 12, 2023</td>
              </tr>
              <tr style="background-color: white">
                <td>Finalist Notification and Verification</td><td>May 19, 2023</td>
              </tr>
              <tr style="background-color: white">
                <td>Winner Announcement</td><td>Jun 02, 2023</td>
              </tr>
              <tr style="background-color: white">
                <td>Winner Presentation</td><td>Jun 18, 2023</td>
              </tr>
            </tbody>
          </table>
        </p>


        <br>

        
        <h4><b> Award</b></h4>
        <p>
          Teams with the first, second, and third highest mean overall score across all three challenges will be awarded.
          Besides, the team with the most innovative submission judged by a panel of Motional experts will be awarded.
          Please refer to <a href="https://nuplan-devkit.readthedocs.io/en/latest/competition.html#prizes">the prizes and details</a>.
        </p>


        <br>


        <h4><b>Contact</b></h4>
        <p>
          <li style="list-style-type:disc">
            <a href="https://github.com/motional/nuplan-devkit/issues">GitHub issue</a>
          </li>
          <li style="list-style-type:disc">
            Motional, <code>nuScenes@motional.com</code>
          </li>
          <li style="list-style-type:disc">
            Slack channel: <code>todo?</code>
          </li>
        </p>

        <br>


        <h4><b>Related Literature</b></h4>
        <p>
          <li style="list-style-type:disc; font-size: 0.8em;">
            <a href="https://arxiv.org/pdf/2206.03004.pdf">
              Driving in Real Life with Inverse Reinforcement Learning
            </a>
          </li>
          <li style="list-style-type:disc; font-size: 0.8em;">
            <a href="https://openaccess.thecvf.com/content/CVPR2022W/Precognition/papers/Hazard_Importance_Is_in_Your_Attention_Agent_Importance_Prediction_for_Autonomous_CVPRW_2022_paper.pdf">
              Importance Is in Your Attention: Agent Importance Prediction for Autonomous Driving
            </a>
          </li>
        </p>

        <!--
        <div class="scrollable">
          <table>
            <thead>
              <tr>
                <th>Method</th>
                <th>OLS (main metric)</th>
                <th> $mAP_{LC}$</th>
                <th> $mAP_{TE}$</th>
                <th> $mAP_{LCLC}$ </th>
                <th> $mAP_{LCTE}$</th>
                <th> F-Score</th>

              </tr>
            </thead>
            <tbody>
              <tr>
                <td><a href="#">\</a></td>
                <td>\</td>
                <td>\</td>
                <td>\</td>
                <td>\</td>
                <td>\</td>
                <td>\</td>
              </tr>
              <tr>
                <td>\</td>
                <td>\</td>
                <td>\</td>
                <td><a href="#">\</a></td>
                <td>\</td>
                <td>\</td>
                <td>\</td>
              </tr>
              <tr>
                <td><a href="#">\</a></td>
                <td>\</td>
                <td>\</td>
                <td>\</td>
                <td>\</td>
                <td>\</td>
                <td>\</td>
              </tr>
              <tr>
                <td><a href="#">\</a></td>
                <td>\</td>
                <td>\</td>
                <td>\</td>
                <td>\</td>
                <td>\</td>
                <td>\</td>
              </tr>
            </tbody>
          </table>
        </div> -->


<!--         <div>
          <div class="wsite-multicol">
            <div class="wsite-multicol-table-wrap" style="margin:0 -15px;">
              <table class="wsite-multicol-table">
                <tbody class="wsite-multicol-tbody">
                  <tr class="wsite-multicol-tr">
                    <td class="wsite-multicol-col" style="width:36.598465473146%; padding:0 15px;">



                      <div>
                        <div class="wsite-image wsite-image-border-none "
                          style="padding-top:10px;padding-bottom:10px;margin-left:0;margin-right:0;text-align:center">
                          <a>
                            <img src="./images/challenge/lane.gif" alt="Picture"
                              style="width:auto;max-width:100%;height:240px;" />
                          </a>
                          <div style="display:block;font-size:90%"></div>
                        </div>
                      </div>

                    </td>
                    <td class="wsite-multicol-col" style="width:73.401534526854%; padding:0 15px;">

                       <div class="paragraph">         <p class="bts" target="_blank" style="font-size: 3em;">nuPlan Planning Challenge</p> 
                      <div class="paragraph"> <a class="bts" target="_blank" style="font-size: 2em; line-height: 1.4">3D
                          Lane Detection</a>

                        <p itemprop="description" style="font-size: 1.2em;">We annotate 3D lane centerlines and include the F-Score for evaluating predicted
                          results of undirected lane centerlines.
                          Furthermore, we define the subtask of 3D lane detection as detecting directed 3D lane
                          centerlines from the given multi-view images covering the whole horizontal FOV.
                        </p>

                    </td>
                  </tr>
                </tbody>
              </table>
            </div>
          </div>
        </div>


        <div>
          <div class="wsite-multicol">
            <div class="wsite-multicol-table-wrap" style="margin:0 -15px;">
              <table class="wsite-multicol-table">
                <tbody class="wsite-multicol-tbody">
                  <tr class="wsite-multicol-tr">
                    <td class="wsite-multicol-col" style="width:36.598465473146%; padding:0 15px;">

                      <div>
                        <div class="wsite-image wsite-image-border-none "
                          style="padding-top:10px;padding-bottom:10px;margin-left:0;margin-right:0;text-align:center">
                          <a>
                            <img src="./images/challenge/traffic_element.gif" alt="Picture"
                              style="width:auto;max-width:100%;height:240px;" />
                          </a>
                          <div style="display:block;font-size:90%"></div>
                        </div>
                      </div>

                    </td>
                    <td class="wsite-multicol-col" style="width:73.401534526854%; padding:0 15px;">

                      <div class="paragraph"> <a class="bts" target="_blank"
                          style="font-size: 2em; line-height: 1.4">Traffic Element Recognition</a>

                        <p itemprop="description" style="font-size: 1.2em;">
                          The attribute represents the semantic meaning of a traffic element, such as the red color of
                          a traffic light.
                          In this subtask, on the given image in the front view, the location of traffic elements
                          (traffic lights and road signs) and their attributes are demanded to be perceived
                          simultaneously.
      
                        </p>

                    </td>
                  </tr>
                </tbody>
              </table>
            </div>
          </div>
        </div>

        <div>
          <div class="wsite-multicol">
            <div class="wsite-multicol-table-wrap" style="margin:0 -15px;">
              <table class="wsite-multicol-table">
                <tbody class="wsite-multicol-tbody">
                  <tr class="wsite-multicol-tr">
                    <td class="wsite-multicol-col" style="width:36.598465473146%; padding:0 15px;">

                      <div>
                        <div class="wsite-image wsite-image-border-none "
                          style="padding-top:10px;padding-bottom:10px;margin-left:0;margin-right:0;text-align:center">
                          <a>
                            <img src="./images/challenge/topology.gif" alt="Picture"
                              style="width:auto;max-width:100%;height:240px;" />
                          </a>
                          <div style="display:block;font-size:90%"></div>
                        </div>
                      </div>

                    </td>
                    <td class="wsite-multicol-col" style="width:73.401534526854%; padding:0 15px;">

                      <div class="paragraph"> <a class="bts" target="_blank"
                          style="font-size: 1em;">
                        Topology Recognition</a>

                        <p itemprop="description" style="font-size: 1.2em;">We first define the task of recognizing
                          topology relationships in the field of autonomous driving.
                          Given multi-view images, the model learns to recognize the topology relationships among lane
                          centerlines and between lane centerlines and traffic elements.
                          In our case, both vertices and edges are unknown for the model.
                          Thus, lane centerlines and traffic elements are needed to be detected first, and then the
                          topology relationships are built.
                        </p>

                    </td>
                  </tr>
                </tbody>
              </table>
            </div>
          </div>
        </div> -->



        <!-- ################################################################################################ -->



        <!--<h3><b><p class="btb" target="_blank" id="Leaderboard" style="font-size: 2.5em;">Leaderboard</p></b></h3>

        The following result is a mirrored version from test server. For latest results, please refer to TODO. <br><br><br>

        <div class="scrollable">
          <table>
            <thead>
              <tr>
                <th>Method</th>
                <th>OLS (main metric)</th>
                <th> $mAP_{LC}$</th>
                <th> $mAP_{TE}$</th>
                <th> $mAP_{LCLC}$ </th>
                <th> $mAP_{LCTE}$</th>
                <th> F-Score</th>

              </tr>
            </thead>
            <tbody>
              <tr>
                <td><a href="#">\</a></td>
                <td>\</td>
                <td>\</td>
                <td>\</td>
                <td>\</td>
                <td>\</td>
                <td>\</td>
              </tr>
              <tr>
                <td>\</td>
                <td>\</td>
                <td>\</td>
                <td><a href="#">\</a></td>
                <td>\</td>
                <td>\</td>
                <td>\</td>
              </tr>
              <tr>
                <td><a href="#">\</a></td>
                <td>\</td>
                <td>\</td>
                <td>\</td>
                <td>\</td>
                <td>\</td>
                <td>\</td>
              </tr>
              <tr>
                <td><a href="#">\</a></td>
                <td>\</td>
                <td>\</td>
                <td>\</td>
                <td>\</td>
                <td>\</td>
                <td>\</td>
              </tr>
            </tbody>
          </table>
        </div>-->


        <!-- ################################################################################################ -->


        <!-- <h3><b>
            <p class="btb" target="_blank" id="starter_code" style="font-size: 2.5em;">Starter Code</p>
          </b></h3>

          Coming soon.

        <p>
          To evaluate performances on different aspects of the task, several metrics are adopted:<br>
          1. $mAP_{LC}$ for mAP on directed lane centerlines<br>
          2. $mAP_{TE}$ for mAP on traffic elements<br>
          3. $mAP_{LCLC}$ for mAP on topology among lane centerlines<br>
          4. $mAP_{LCTE}$ for mAP on topology between lane centerlines and traffic elements.
        </p>

        <br><br>-->




        <!--<h3><b><p class="btb" target="_blank" id="submission" style="font-size: 2.5em;">Submission </p></b></h3>

        Coming soon.-->



        <br><br><br>
        <hr>
        <br><br><br>



        <h3><b class="btb" target="_blank" id="rules" style="font-size: 2.5em;">General Rules </b></h3>

        <p>
          Please refer to <a href="https://docs.google.com/document/d/18wEN6XdSW2VpVgSo0hHEKPN6KPptqvOUv5Znc2_lB3o/edit?usp=sharing">rules</a>.
        </p>



      </div>
      <!-- ################################################################################################ -->
      <!-- ################################################################################################ -->



      <!-- ################################################################################################ -->
      <!-- / main body -->
      <div class="clear"></div>
    </main>
  </div>
  <!-- ################################################################################################ -->
  <!-- ################################################################################################ -->

  <div class="wrapper row4">
    <footer id="footer" class="hoc clear">
      <!-- ################################################################################################ -->
      <div class="center btmspace-50">
        <h6 class="heading">OpenDriveLab</h6>
        <nav>
          <ul class="nospace inline pushright uppercase">
            <li><a href="http://opendrivelab.com/"><i class="fas fa-lg fa-home"></i></a></li>
          </ul>
        </nav>
      </div>
      <!-- ################################################################################################ -->
    </footer>
  </div>
  <!-- ################################################################################################ -->
  <!-- ################################################################################################ -->
  <!-- ################################################################################################ -->
  <div class="wrapper row5">
    <div id="copyright" class="hoc clear">
      <!-- ################################################################################################ -->
      <p class="fl_left">Copyright &copy; 2023 - All Rights Reserved - OpenDriveLab</p>

      <!-- ################################################################################################ -->
    </div>
  </div>
  <!-- ################################################################################################ -->
  <!-- ################################################################################################ -->
  <!-- ################################################################################################ -->
  <a id="backtotop" href="#top"><i class="fas fa-chevron-up"></i></a>
  <!-- JAVASCRIPTS -->
  <script src="../layout/scripts/jquery.min.js"></script>
  <script src="../layout/scripts/jquery.backtotop.js"></script>
  <script src="../layout/scripts/jquery.mobilemenu.js"></script>
  <script src="../layout/editor.md/editormd.min.js"></script>
  <script src="https://cdn.bootcss.com/jquery/3.4.1/jquery.js"></script>

  <script src="https://cdn.jsdelivr.net/npm/marked@3.0.0/marked.min.js"></script>
  <script>
    var m = document.querySelectorAll('code[markdown]');
    for (var i = 0; i < m.length; i++) {
      m[i].outerHTML = '<div>' + marked(m[i].innerHTML) + '</div>';
    }
  </script>

</body>

</html>

<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="UTF-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport"
        content="width=device-width,initial-scale=1.0,minimum-scale=1.0,maximum-scale=1.0,user-scalable=no" />
<title>OpenDriveLab | Autonomous Driving at Shanghai AI Lab</title>
<!-- <link rel="icon" type="image/png" href="style/img/team_logo.png"> -->
<link href="style/css/all.css" rel="stylesheet" type="text/css" media="all">
</head>

<body class="home">
<div class="header"> <a class="head_fanhui" href="index.html"></a>
  <div class="rnav m"></div>
  <a class="logo" href="index.html"></a>
  <div class="qh_langw">
    <div class="qh_lang"><a href="index.html#FAQ">FAQ</a></div>
    <div class="qh_lang"><a href="index_cn.html">中</a><a
                    href="index.html" class="this">EN</a></div>
  </div>
</div>
<div class="rnav_br"></div>
<div class="bannerw">
<div class="banner" style="background-image: url(style/img/index_banner.jpg);">
  <div class="banner_dian"></div>
 
  <div class="banner_textw">
    <div class="bg">
      <div class="juzhongduiqi">
        <div>
          <div class="t_text"> <img src="style/img/auto.svg" class="title_auto" /> <img src="style/img/challeng.svg" class="title_challeng" /> </div>
          <p>In conjunction with</p>
          <p><img src="style/img/cvpr2023.svg" class="titel_cvpr" data-swiper-parallax-x="-1600" /></p>
          <div class="banner_text">
            <p>
              <a href="End-to-End.html">End-to-End Autonomous Driving Workshop</a>
            </p>
            <p>
<a href="#">Vision-Centric Autonomous Driving Workshop</a>

            </p>
          </div>
          <p class="r_time">June 18, Vancouver, Canada</p>
          <p><img src="style/img/sh_logo.svg" class=" banner_img" data-swiper-parallax-x="-1600" /></p>
          <br />
          <span class="lj_button" data-swiper-parallax-x="-4000"  data-hd="#Contact">Contact</span> <span class="lj_button2" data-swiper-parallax-x="-4000"  data-hd="#Participation">Participation</span> </div>
      </div>
    </div>
  </div>
  
</div>

<div class="r_ul">
  <ul class="bg">
    <li class="this" data-gd=".bg_why">Overview</li>
    <li data-gd="#Track1">OpenLane Topology</li>
    <li data-gd="#Track2">Online HD Map Construction</li>
    <li data-gd="#Track3">3D Occupancy Prediction</li>
    <li data-gd="#Track4">nuPlan Planning</li>
    <li data-gd="#rules">General Rules </li>
  </ul>
</div>
</div>
<!-- ################################################################################################ -->
<div class="bg_imgx">
  <div class="bg_why">
    <div class="bg"> 
      
      <!-- Overview -->
      
      <h3><b class="title" target="_blank" id="Overview"> Overview </b></h3>
      <br>
      <h4><b>Why these Challenges?</b></h4>
      <p> Autonomous driving is developing fast.
        Although still deemed important, the requirement for cutting-edge algorithms is no longer to achieve as
        high as mAP for object detectors, or to recognize lanes as conventional segmentation.
        We believe the
        <topic>future</topic>
        of autonomous driving algorithms is to
        <topic>bond perception
          closely with planning</topic>
        . 
        <!--The goal of each module (object detection, lane line recognition, etc.) in perception is to serve better planning. --> 
        As such, we introduce four
        <topic>curated, brand-new</topic>
        challenges following such a philosophy. </p>
    </div>
    <div class="why_list">
      <ul>
        <li>
          <h2>OpenLane Topology Challenge</h2>
          Go beyond conventional lane line detection as segmentation.
          Recognizing lanes as an abstraction of the scene - <code>centerline</code>, and building the
          topology between lanes and traffic elements.
          Such a <code>topology</code> is to facilitate planning and routing. </li>
        <li>
          <h2>Online HD Map Construction Challenge</h2>
          Traditional mapping pipelines require a vast amount of human effort to maintain, which limits their
          scalability.
          This task aims to dynamically construct local <code>maps</code> with rich semantics based on onboard
          sensors.
          The vectorized map can be further utilized by downstream tasks. </li>
        <li>
          <h2>3D Occupancy Prediction Challenge</h2>
          The representation of 3D bounding boxes is not enough to describe general objects (obstacles). 
          <!-- for autonomous driving.  --> 
          Instead, inspired by the concept in Robotics, we deem general object detection as an <code>occupancy</code> representation to cover more irregularly shaped objects (e.g., protruding).
          The output could also be fed as cost volume for planning.
          This idea is also endorsed by <a href="https://www.mobileye.com/ces-2023">Mobileye at CES 2023</a> and <a href="https://www.youtube.com/watch?v=ODSJsviD_SU">Tesla AI Day 2022</a>. </li>
        <li>
          <h2>nuPlan Planning Challenge</h2>
          To verify the effectiveness of the newly-designed modules in perception, we need an ultimate
          planning framework with
          a <code>closed-loop</code> setting.
          Previous motion planning benchmarks focus on short-term motion forecasting and are limited to
          open-loop evaluation. <code>nuPlan</code> introduces long-term planning of the ego vehicle and corresponding metrics. </li>
      </ul>
    </div>
  </div>
  <br>
  <div class="bg"> <img alt="motivation" src="style/img/overview_t.jpg"   class="motivation">
    <h3 class="mot_ts">Motivation of the Challenges: bond
      perception more closely with planning.</h3>
  </div>
  <div class="track_nav">
    <dl data-hd="#Track1">
      <dt>Track 1</dt>
      <dd>OpenLane Topology</dd>
    </dl>
    <dl data-hd="#Track2">
      <dt>Track 2</dt>
      <dd>Online HD Map Construction</dd>
    </dl>
    <dl data-hd="#Track3">
      <dt>Track 3</dt>
      <dd>3D Occupancy Prediction</dd>
    </dl>
    <dl data-hd="#Track4">
      <dt>Track 4</dt>
      <dd>nuPlan Planning</dd>
    </dl>
  </div>
</div>

<div class="bg_huise kin Contact_br">
  <div class="bg"> 
    
    <!-- contact -->
    
    <h4><b id="Contact">Contact</b></h4>
    <p> <a href="mailto:workshop-e2e-ad@googlegroups.com" class="h_imga"> <img data-src="https://img.shields.io/badge/email-Send-important?logo=gmail&amp;" alt="Send E-mail"
                        class="h_img"> </a> Contact us via <code>workshop-e2e-ad@googlegroups.com</code> with the prefix [CVPR 2023 E2EAD]. </p>
    <p> <a href="https://join.slack.com/t/opendrivelab/shared_invite/zt-1rcp42b35-Wc5I0MhUrahlM5qDeJrVqQ"  class="h_imga"> <img data-src="https://img.shields.io/badge/Slack-Join-important?logo=slack&amp;" alt="Join Slack"
                        class="h_img"> </a> Join Slack to chat with Challenge organizers. Please follow the guidelines in <code>#general</code> and
      join the track-specific channels. </p>
    <p> <a href="images/challenge/wechatgroup.jpg"  class="h_imga"> <img data-src="https://img.shields.io/badge/WeChat-Join-important?logo=wechat&amp;" alt="Join Wechat"
                        class="h_img"> </a> Join WeChat group to chat with Challenge organizers. </p>
    <br>
    
    <!-- <h4><b id="Feedback">Feedback</b></h4>
        <p>
          Filling out this <a href="https://docs.google.com/forms/d/e/1FAIpQLSepfNu34EF80BIA7DwbqVOUD3hCytIXAU42gIIXna3OwiTlgA/viewform?usp=sf_link">form</a> for <code>sign-up or feedback</code>.
        </p>
        

        <br> --> 
    
    <!-- participate -->
    
    <h4><b id="Participation">Participation</b></h4>
    <p> For participation, you can create a team at EvalAI, and then make a submission.
      A valid submission would be automatically viewed as a successful participation.
      No more than <b>ten</b> individuals are allowed in a team.
      For more details please refer to <a href="https://opendrivelab.com/AD23Challenge.html#FAQ">FAQ</a> and
      description in each track. </p>
    <button class="btn_from" > <i class="tb"></i> Participation</button>
    <div class="open_from"> <div class="close"></div>
      <div class="open_from_in">
     
      <iframe
                    src="https://docs.google.com/forms/d/e/1FAIpQLSepfNu34EF80BIA7DwbqVOUD3hCytIXAU42gIIXna3OwiTlgA/viewform?embedded=true"
                   frameborder="0" >正在加载…</iframe>
    </div>
    </div>
    <br>
    <hr>
    <br>
    
    <!-- host -->
    
    <h4><b>Host</b></h4>
    <p> The year 2023's edition of the Challenge is hosted by: </p>
    <br>
    <div class="link_logo">
      <ul>
        <li> <a href="https://opendrivelab.com" target="_blank"> <img src="style/img/link_1.svg">
          <p>OpenDriveLab at Shanghai AI Lab </p>
          </a> </li>
        <li> <a href="http://group.iiis.tsinghua.edu.cn/~marslab/#" target="_blank"> <img src="style/img/link_2.svg">
          <p>MARS Lab at Tsinghua Universit </p>
          </a> </li>
        <li> <a href="http://group.iiis.tsinghua.edu.cn/~marslab/#" target="_blank"> <img src="style/img/link_3.svg">
          <p>nuPlan team from Motional </p>
          </a> </li>
      </ul>
    </div>
  </div>
</div>

<div class="bg"> 
  
  <!-- track 1 -->
  
  <h3><b class="title" target="_blank" id="Track1"> Track 1<br>
    OpenLane Topology </b></h3>
  <a href="https://github.com/OpenDriveLab/OpenLane-V2"> <img data-src="https://img.shields.io/badge/website-GitHub-darkgreen" alt="GitHub" class="h_img"> </a> <a href="https://github.com/OpenDriveLab/OpenLane-V2"> <img data-src="https://img.shields.io/github/stars/OpenDriveLab/OpenLane-V2?style=social" alt="GitHub"
                    class="h_img"> </a> <a href="https://github.com/OpenDriveLab/OpenLane-V2"> <img data-src="https://img.shields.io/github/forks/OpenDriveLab/OpenLane-V2?style=social" alt="GitHub"
                    class="h_img"> </a> <a href="https://eval.ai/web/challenges/challenge-page/1925"> <img data-src="https://img.shields.io/badge/submission-EvalAI-darkgreen" alt="EvalAI" class="h_img"> </a> <br>
  <br>
  <br>
  <h4><b>Task Description</b></h4>
  <p> The <a href="https://github.com/OpenDriveLab/OpenLane-V2">OpenLane-V2</a> dataset* is the perception and
    reasoning benchmark for scene structure in autonomous driving.
    Given multi-view images covering the whole panoramic field of view,
    participants are required to deliver not only perception results of lanes and traffic elements but also
    topology relationships among lanes and between lanes and traffic elements simultaneously. </p>
  <p class="footer_ts">* The dataset, OpenLane-V2 at Shanghai AI Lab, is named as RoadGenome at Huawei and
    publically as OpenLane-Huawei.</p>
  <p></p>
  <br>
  <h4><b>Participation</b></h4>
  <p> The primary metric is <a href="https://github.com/OpenDriveLab/OpenLane-V2#task">OpenLane-V2 Score
    (OLS)</a>, which comprises evaluations on three sub-tasks.
    On the website, we provide tools for <a href="https://github.com/OpenDriveLab/OpenLane-V2/blob/master/docs/devkit.md#openlanev2dataset">data
    access</a>, <a href="https://github.com/OpenDriveLab/OpenLane-V2#train-a-model">training models</a>, <a
                    href="https://github.com/OpenDriveLab/OpenLane-V2/blob/master/docs/devkit.md#openlanev2evaluation">evaluations</a>,
    and <a
                    href="https://github.com/OpenDriveLab/OpenLane-V2/blob/master/docs/devkit.md#openlanev2visualization">visualization</a>.
    To submit your results on <a
                    href="https://eval.ai/web/challenges/challenge-page/1925/overview">EvalAI</a>, please
    follow the <a
                    href="https://github.com/OpenDriveLab/OpenLane-V2/blob/master/docs/submission.md#submission">submission
    instructions</a>. </p>
  <br>
  <h4><b>Important dates</b></h4>
  <p> </p>
  <table class="itable">
    <tbody>
      <tr >
        <td>Challenge Period Open</td>
        <td>Mar 15, 2023</td>
      </tr>
      <tr >
        <td>Challenge Period End</td>
        <td>May 26, 2023</td>
      </tr>
      <tr >
        <td>Notification</td>
        <td>May 28, 2023</td>
      </tr>
      <tr >
        <td>Technical Report Deadline</td>
        <td>Jun 09, 2023</td>
      </tr>
      <tr >
        <td>Winner Announcement</td>
        <td>Jun 11, 2023</td>
      </tr>
    </tbody>
  </table>
  <p class="footer_ts">* &nbsp; All due at 23:59 UTC+8. <br>
    ** The test server will remain open after the challenge.</p>
  <p></p>
  <br>
  <h4><b>Leaderboard</b></h4>
  <p> </p>
  <div class="scrollable">
    <table style="text-align: center;">
   
      <thead>
        <tr>
          <th style="background-color: rgb(14, 104, 14); ">Rank</th>
          <th style="background-color: rgb(14, 104, 14); ">Method</th>
          <th style="background-color: rgb(14, 104, 14);"><b>OLS <i>(primary metric)</i></b></th>
          <th style="background-color: rgb(14, 104, 14);"> <span class="mx_num"> DET<sub>l</sub></span> </th>
          <th style="background-color: rgb(14, 104, 14);"><span class="mx_num">DET <sub>t</sub></span> </th>
          <th style="background-color: rgb(14, 104, 14);"><span class="mx_num">TOP<sub>ll</sub></span> </th>
          <th style="background-color: rgb(14, 104, 14);"><span class="mx_num">TOP<sub>lt</sub></span> </th>
          <th style="background-color: rgb(14, 104, 14);">F-Score*</th>
        </tr>
      </thead>
      <tbody>
        <tr>
          <td>1</td>
          <td>BeingStrong</td>
          <td>0.25</td>
          <td>0.12</td>
          <td>0.54</td>
          <td>0.00</td>
          <td>0.08</td>
          <td>0.24</td>
        </tr>
        <tr>
          <td>2</td>
          <td>anonymous_team</td>
          <td>0.02</td>
          <td>0.00</td>
          <td>0.05</td>
          <td>0.00</td>
          <td>0.00</td>
          <td>0.09</td>
        </tr>
        <tr>
          <td>3</td>
          <td>boketto</td>
          <td>0.00</td>
          <td>0.00</td>
          <td>0.00</td>
          <td>0.00</td>
          <td>0.00</td>
          <td>0.00</td>
        </tr>
      </tbody>
    </table>
  </div>
  <p class="footer_ts">* &nbsp; For the real-time leaderboard please refer to <a href="https://eval.ai/web/challenges/challenge-page/1925/leaderboard">EvalAI</a>. <br>
    ** <b>F-Score</b> for lane detection is not taken into consideration in both the challenge and leaderboard.</p>
  <p></p>
  <br>
  <h4><b>Award</b></h4>

  <table class="itable">
    <tbody>
      <tr>
        <td>1<sup>st</sup> Place</td>
        <td>USD $15,000</td>
      </tr>
     <tr>
      <td>2<sup>nd</sup> Place</td>
      <td>USD $5,000</td>
     </tr>
     <tr>
      <td>Innovation Prize</td>
      <td>USD $5,000</td>
     </tr>
   
    </tbody>
  </table>

  <!-- <p> To be announced. </p> -->
    <!-- For verified finalists, teams with the first and second highest scores will be awarded.
          Besides, the team with the most innovative method will be awarded.
          The prizes will be announced. --> 
    
  <br>
  <h4><b>Contact</b></h4>
  <p> </p>
  <!-- <li> Yang Li, <code>liyang@opendrivelab.com</code> </li> -->
  <li> Huijie Wang, <code>wanghuijie@pjlab.org.cn</code> </li>
  <li> Slack channel: <code>#openlane-challenge-2023</code> </li>
  <p></p>
  <br>
  <h4><b>Related Literature</b></h4>
  <p> </p>
  <li> <a
                    href="https://openaccess.thecvf.com/content/ICCV2021/papers/Can_Structured_Birds-Eye-View_Traffic_Scene_Understanding_From_Onboard_Images_ICCV_2021_paper.pdf"> Structured Bird's-Eye-View Traffic Scene Understanding From Onboard Images </a> </li>
  <li> <a href="https://arxiv.org/pdf/2203.11089.pdf"> PersFormer: 3D Lane Detection via Perspective Transformer and the OpenLane Benchmark </a> </li>
  <li> <a href="https://arxiv.org/pdf/2208.14437.pdf"> MapTR: Structured Modeling and Learning for Online Vectorized HD Map Construction </a> </li>
  <p></p>
  <br>
  <br>
  <br>
  
</div>
<div class="bg_huise">
  <div class="bg">
  <!-- track 2 -->
  <br>
  <br>
  <br>
  <h3><b class="title" target="_blank" id="Track2"> Track 2<br>
    Online HD Map Construction </b></h3>
  <a href="https://github.com/Tsinghua-MARS-Lab/Online-HD-Map-Construction-CVPR2023"> <img data-src="https://img.shields.io/badge/website-GitHub-darkcyan" alt="GitHub" class="h_img"> </a> <a href="https://github.com/Tsinghua-MARS-Lab/Online-HD-Map-Construction-CVPR2023"> <img data-src="https://img.shields.io/github/stars/Tsinghua-MARS-Lab/Online-HD-Map-Construction-CVPR2023?style=social"
                    alt="GitHub" class="h_img"> </a> <a href="https://github.com/Tsinghua-MARS-Lab/Online-HD-Map-Construction-CVPR2023"> <img data-src="https://img.shields.io/github/forks/Tsinghua-MARS-Lab/Online-HD-Map-Construction-CVPR2023?style=social"
                    alt="GitHub" class="h_img"> </a> <a href="https://eval.ai/web/challenges/challenge-page/1954/overview"> <img data-src="https://img.shields.io/badge/submission-EvalAI-darkcyan" alt="EvalAI" class="h_img"> </a> <br>
  <br>
  <br>
  <h4><b>Task Description</b></h4>
  <p> Compared to conventional lane detection, the constructed HD map provides more semantics information with
    multiple categories.
    Vectorized polyline representations are adopted to deal with complicated and even irregular road
    structures.
    Given inputs from onboard sensors (cameras), the goal is to construct the complete local HD map. </p>
  <br>
  <h4><b>Participation</b></h4>
  <p> The primary metric is mAP based on Chamfer distance over three categories, namely lane divider,
    boundary, and pedestrian crossing.
    Please refer to our <a
                    href="https://github.com/Tsinghua-MARS-Lab/Online-HD-Map-Construction-CVPR2023">GitHub</a> for
    details on <a
                    href="https://github.com/Tsinghua-MARS-Lab/Online-HD-Map-Construction-CVPR2023/blob/master/resources/docs/data.md">data</a> and <a
                    href="https://github.com/Tsinghua-MARS-Lab/Online-HD-Map-Construction-CVPR2023/blob/master/resources/docs/get_started.md#evaluation">evaluation</a>.
    Submission is conducted on <a
                    href="https://eval.ai/web/challenges/challenge-page/1954/overview">EvalAI</a>. </p>
  <br>
  <h4><b>Important dates</b></h4>
  <p> </p>
  <table class="itable">
    <tbody>
      <tr >
        <td>Challenge Period Open</td>
        <td>Mar 15, 2023</td>
      </tr>
      <tr >
        <td>Challenge Period End</td>
        <td>May 26, 2023</td>
      </tr>
      <tr >
        <td>Notification</td>
        <td>May 28, 2023</td>
      </tr>
      <tr >
        <td>Technical Report Deadline</td>
        <td>Jun 09, 2023</td>
      </tr>
      <tr >
        <td>Winner Announcement</td>
        <td>Jun 11, 2023</td>
      </tr>
    </tbody>
  </table>
  <p class="footer_ts">* &nbsp; All due at 23:59 UTC+8. <br>
    ** The test server will remain open after the challenge.</p>
  <p></p>
  <br>
  <h4><b>Leaderboard</b></h4>
  <p> </p>
  <div class="scrollable">
    <table style="text-align: center;">
      <!-- id="keywords" cellspacing="0" cellpadding="0" -->
      <thead>
        <tr>
          <th style="background-color: rgb(1, 126, 126); ">Rank</th>
          <th style="background-color: rgb(1, 126, 126); ">Method</th>
          <th style="background-color: rgb(1, 126, 126);"> <b>mAP <i>(primary metric)</i></b> </th>
          <th style="background-color: rgb(1, 126, 126);"> <span class="mx_num"> AP<sub>div<em>*</em> </sub> </span></th>
          <th style="background-color: rgb(1, 126, 126);"> <span class="mx_num"> AP<sub>bound<em>*</em></sub> </span> </th>
          <th style="background-color: rgb(1, 126, 126);"> <span class="mx_num"> AP<sub>pc<em>*</em></sub> </span> </th>
        </tr>
      </thead>
      <tbody>
        <tr>
          <td>1</td>
          <td>Host_75980_Team</td>
          <td>42.11</td>
          <td>50.11</td>
          <td>40.26</td>
          <td>35.95</td>
        </tr>
      </tbody>
    </table>
  </div>
  <p class="footer_ts">* &nbsp; For the real-time leaderboard please refer to <a href="https://eval.ai/web/challenges/challenge-page/1954/leaderboard">EvalAI</a>. <br>
    ** <b>AP*</b> on different classes: lane divider (div), boundary (bound), and pedestrian crossing (pc). </p>
 
  <br>
  <h4><b>Award</b></h4>
  <table class="itable">
    <tbody>
      <tr>
        <td>1<sup>st</sup> Place</td>
        <td>USD $15,000</td>
      </tr>
     <tr>
      <td>2<sup>nd</sup> Place</td>
      <td>USD $5,000</td>
     </tr>
     <tr>
      <td>Innovation Prize</td>
      <td>USD $5,000</td>
     </tr>
   
    </tbody>
  </table>
  <!-- <p> To be announced. </p> -->
  <br>
  <h4><b>Contact</b></h4>
  <p> </p>
  <li> Tianyuan Yuan, <code>yuantianyuan01@gmail.com</code> </li>
  <!-- <li> Yicheng Liu, <code>moooooore66@gmail.com</code> </li> -->
  <li> Slack channel: <code>#map-challenge-2023</code> </li>
  <p></p>
  <br>
  <h4><b>Related Literature</b></h4>
  <p> </p>
  <li> <a href="https://arxiv.org/pdf/2107.06307.pdf"> HDMapNet: An Online HD Map Construction and Evaluation Framework </a> </li>
  <li> <a href="https://arxiv.org/pdf/2206.08920.pdf"> VectorMapNet: End-to-end Vectorized HD Map Learning </a> </li>
  <li> <a href="https://arxiv.org/pdf/2301.04470.pdf"> InstaGraM: Instance-level Graph Modeling for Vectorized HD Map Learning </a> </li>
  <p></p>
  <br>
  <br>
  <br>
 
 
  </div></div>
 
    <div class="bg">
  <!-- track 3 -->
  <br>
  <br>
  <br>
  <h3><b class="title" target="_blank" id="Track3"> Track 3<br>
    3D Occupancy Prediction </b></h3>
  <a
                href="https://github.com/CVPR2023-Occupancy-Prediction-Challenge/CVPR2023-Occupancy-Prediction-Challenge"> <img data-src="https://img.shields.io/badge/website-GitHub-darkred" alt="GitHub" class="h_img"> </a> <a
                href="https://github.com/CVPR2023-Occupancy-Prediction-Challenge/CVPR2023-Occupancy-Prediction-Challenge"> <img data-src="https://img.shields.io/github/stars/CVPR2023-Occupancy-Prediction-Challenge/CVPR2023-Occupancy-Prediction-Challenge?style=social"
                    alt="GitHub" class="h_img"> </a> <a
                href="https://github.com/CVPR2023-Occupancy-Prediction-Challenge/CVPR2023-Occupancy-Prediction-Challenge"> <img data-src="https://img.shields.io/github/forks/CVPR2023-Occupancy-Prediction-Challenge/CVPR2023-Occupancy-Prediction-Challenge?style=social"
                    alt="GitHub" class="h_img"> </a> <a href="https://eval.ai/web/challenges/challenge-page/1956/overview"> <img data-src="https://img.shields.io/badge/submission-EvalAI-darkred" alt="EvalAI" class="h_img"> </a> <br>
  <br>
  <br>
  <h4><b>Task Description</b></h4>
  <p> Unlike previous perception representations, which depend on predefined geometric primitives or perceived
    data modalities,
    occupancy enjoys the flexibility to describe entities in arbitrary shapes.
    In this track, we provide a large-scale <a
                    href="https://github.com/CVPR2023-Occupancy-Prediction-Challenge/CVPR2023-Occupancy-Prediction-Challenge">occupancy
    benchmark</a>.
    Given multi-view images covering the whole panoramic field of view,
    participants are needed to provide the occupancy state and semantics of each voxel in 3D space for the
    complete scene. </p>
  <br>
  <h4><b>Participation</b></h4>
  <p> The primary metric of this track is mIoU.
    On the <a
                    href="https://github.com/CVPR2023-Occupancy-Prediction-Challenge/CVPR2023-Occupancy-Prediction-Challenge">website</a>,
    we provide detailed information for the dataset, evaluation, and submission instructions.
    The test server is hosted on <a
                    href="https://eval.ai/web/challenges/challenge-page/1956/overview">EvalAI</a>. </p>
  <br>
  <h4><b>Important dates</b></h4>
  <p> </p>
  <table class="itable">
    <tbody>
      <tr >
        <td>Dataset and Devkit Release</td>
        <td>Feb 20, 2023</td>
      </tr>
      <tr >
        <td>Challenge Period Open</td>
        <td>Pending</td>
      </tr>
      <tr >
        <td>Challenge Period End</td>
        <td>Jun 01, 2023</td>
      </tr>
      <tr >
        <td>Notification</td>
        <td>Jun 03, 2023</td>
      </tr>
      <tr >
        <td>Technical Report Deadline</td>
        <td>Jun 10, 2023</td>
      </tr>
      <tr >
        <td>Winner Announcement</td>
        <td>Jun 12, 2023</td>
      </tr>
    </tbody>
  </table>
  <p class="footer_ts">* &nbsp; All due at 23:59 UTC+8. <br>
    ** The test server will remain open after the challenge.</p>
 
  
  <h4><b>Leaderboard</b></h4>
  <p> </p>
  <div class="scrollable">
    <table style="text-align: center;">
      <!-- id="keywords" cellspacing="0" cellpadding="0" -->
      <thead>
        <tr>
          <th style="background-color: rgb(139, 14, 14); ">Rank</th>
          <th style="background-color: rgb(139, 14, 14); ">Method</th>
          <th style="background-color: rgb(139, 14, 14);"><b>mIoU <i>(primary metric)</i></b></th>
          <th style="background-color: rgb(139, 14, 14);"> <b>F-Score</b> * </th>
        </tr>
      </thead>
      <tbody>
        <tr>
          <td>-</td>
          <td>-</td>
          <td>-</td>
          <td>-</td>
        </tr>
      </tbody>
    </table>
  </div>
  <p class="footer_ts">* &nbsp; For the real-time leaderboard please refer to <a href="https://eval.ai/web/challenges/challenge-page/1956/leaderboard">EvalAI</a>. <br>
  
  ** <b>F-Score</b> is not taken into consideration in both the challenge and leaderboard.</p>
 
  <br>
  <h4><b>Award</b></h4>
  <table class="itable">
    <tbody>
      <tr>
        <td>1<sup>st</sup> Place</td>
        <td>USD $15,000</td>
      </tr>
     <tr>
      <td>2<sup>nd</sup> Place</td>
      <td>USD $5,000</td>
     </tr>
     <tr>
      <td>Innovation Prize</td>
      <td>USD $5,000</td>
     </tr>
   
    </tbody>
  </table>
  <!-- <p>  To be announced. </p> -->
    <!-- For verified finalists, teams with the first and second highest scores will be awarded.
          Besides, the team with the most innovative method will be awarded.
          The prizes will be announced. --> 
   
  <br>
  <h4><b>Contact</b></h4>
  <p> </p>
  <li> Xiaoyu Tian, <code>cntxy001@gmail.com</code> </li>
  <li> Chonghao Sima, <code>chonghaosima@gmail.com</code> </li>
  <li> Slack channel: <code>#occupancy-challenge-2023</code> </li>
  <p></p>
  <br>
  <h4><b>Related Literature</b></h4>
  <p> </p>
  <li> <a href="https://arxiv.org/pdf/2003.04618.pdf"> Convolutional Occupancy Networks </a> </li>
  <li> <a href="https://arxiv.org/pdf/2203.03875.pdf"> Occupancy Flow Fields for Motion Forecasting in Autonomous Driving </a> </li>
  <li> <a
                    href="https://openaccess.thecvf.com/content/CVPR2022/papers/Cao_MonoScene_Monocular_3D_Semantic_Scene_Completion_CVPR_2022_paper.pdf"> MonoScene: Monocular 3D Semantic Scene Completion </a> </li>
  <li> <a href="https://arxiv.org/pdf/2301.00527.pdf"> Diffusion Probabilistic Models for Scene-Scale 3D Categorical Data </a> </li>
  <p></p>
  
  <!-- <div class="scrollable">
          <table>
            <thead>
              <tr>
                <th>Method</th>
                <th>OLS (main metric)</th>
                <th> $mAP_{LC}$</th>
                <th> $mAP_{TE}$</th>
                <th> $mAP_{LCLC}$ </th>
                <th> $mAP_{LCTE}$</th>
                <th> F-Score</th>
              </tr>
            </thead>
            <tbody>
              <tr>
                <td><a href="#">\</a></td>
                <td>\</td>
                <td>\</td>
                <td>\</td>
                <td>\</td>
                <td>\</td>
                <td>\</td>
              </tr>
              <tr>
                <td>\</td>
                <td>\</td>
                <td>\</td>
                <td><a href="#">\</a></td>
                <td>\</td>
                <td>\</td>
                <td>\</td>
              </tr>
              <tr>
                <td><a href="#">\</a></td>
                <td>\</td>
                <td>\</td>
                <td>\</td>
                <td>\</td>
                <td>\</td>
                <td>\</td>
              </tr>
              <tr>
                <td><a href="#">\</a></td>
                <td>\</td>
                <td>\</td>
                <td>\</td>
                <td>\</td>
                <td>\</td>
                <td>\</td>
              </tr>
            </tbody>
          </table>
        </div> --> 
  
  <br>
  <br>
  <br>
  

  </div>
  <div class="bg_huise">
    <br>
    <br>
    <br>
    <div class="bg">
  <!-- track 4 -->
  
  <h3><b class="title" target="_blank" id="Track4"> Track 4<br>
    nuPlan Planning </b></h3>
  <a href="https://github.com/motional/nuplan-devkit"> <img data-src="https://img.shields.io/badge/website-GitHub-darkblue" alt="GitHub" class="h_img"> </a> <a href="https://github.com/motional/nuplan-devkit"> <img data-src="https://img.shields.io/github/stars/motional/nuplan-devkit?style=social" alt="GitHub"
                    class="h_img"> </a> <a href="https://github.com/motional/nuplan-devkit"> <img data-src="https://img.shields.io/github/forks/motional/nuplan-devkit?style=social" alt="GitHub"
                    class="h_img"> </a> <a href="https://eval.ai/web/challenges/challenge-page/1856/CVPR 2023 "> <img data-src="https://img.shields.io/badge/submission-EvalAI-darkblue" alt="EvalAI" class="h_img"> </a> <br>
  <br>
  <br>
  <h4><b>Task Description</b></h4>
  <p> Previous benchmarks focus on short-term motion forecasting and are limited to open-loop evaluation. <a href="https://www.nuscenes.org/nuplan">nuPlan</a> introduces long-term planning of the ego vehicle
    and corresponding metrics.
    Provided as docker containers, submissions are deployed for simulation and evaluation. </p>
  <br>
  <h4><b>Participation</b></h4>
  <p> The primary metric is the mean score over three increasingly complex modes: <a
                    href="https://nuplan-devkit.readthedocs.io/en/latest/competition.html#challenge-1-open-loop">open-loop</a>, <a
                    href="https://nuplan-devkit.readthedocs.io/en/latest/competition.html#challenge-2-closed-loop-non-reactive-agents">closed-loop
    non-reactive agents</a>,
    and <a
                    href="https://nuplan-devkit.readthedocs.io/en/latest/competition.html#challenge-3-closed-loop-reactive-agents">closed-loop
    reactive agents</a>.
    Participants can follow the <a
                    href="https://nuplan-devkit.readthedocs.io/en/latest/competition.html#getting-started">steps</a> to
    begin the competition.
    To submit your results on <a
                    href="https://eval.ai/web/challenges/challenge-page/1856/overview">EvalAI</a>, please
    follow the <a
                    href="https://nuplan-devkit.readthedocs.io/en/latest/competition.html#making-a-submission">submission
    instructions</a>. </p>
  <br>
  <h4><b>Important dates</b></h4>
  <p> </p>
  <table class="itable">
    <tbody>
      <tr >
        <td>Test Phase End</td>
        <td>May 18, 2023</td>
      </tr>
      <tr >
        <td>Notification and Verification</td>
        <td>May 19, 2023</td>
      </tr>
      <tr >
        <td>Winner Announcement</td>
        <td>Jun 02, 2023</td>
      </tr>
      <tr >
        <td>Winner Presentation</td>
        <td>Jun 18, 2023</td>
      </tr>
    </tbody>
  </table>
  <p></p>
  <br>
  <h4><b>Leaderboard</b></h4>
  <p> </p>
  <div class="scrollable">
    <table style="text-align: center;">
      <thead>
        <tr>
          <th style="background-color: rgb(25, 25, 145); ">Rank</th>
          <th style="background-color: rgb(25, 25, 145); ">Team</th>
          <th style="background-color: rgb(25, 25, 145);"><b>mean score <i>(primary metric)</i></b></th>
          <th style="background-color: rgb(25, 25, 145);">Challenge 1</th>
          <th style="background-color: rgb(25, 25, 145);">Challenge 2</th>
          <th style="background-color: rgb(25, 25, 145);">Challenge 3</th>
        </tr>
      </thead>
      <tbody>
        <tr>
          <td>1</td>
          <td>Host_68305_Team <i>(Baseline)</i></td>
          <td>0.15</td>
          <td>0.15</td>
          <td>0.39</td>
          <td>0.61</td>
        </tr>
      </tbody>
    </table>
  </div>
  <p class="footer_ts">* For the real-time leaderboard please refer to <a href="https://eval.ai/web/challenges/challenge-page/1856/leaderboard">EvalAI</a>.</p>
  <p></p>
  <br>
  <h4><b>Award</b></h4>

  <table class="itable">
    <tbody>
      <tr>
        <td>1<sup>st</sup> Place</td>
        <td>USD $10,000</td>
      </tr>
     <tr>
      <td>2<sup>nd</sup> Place</td>
      <td>USD $8,000</td>
     </tr>
     <tr>
      <td>3<sup>nd</sup> Place</td>
      <td>USD $5,000</td>
     </tr>
     <tr>
      <td>Innovation Prize</td>
      <td>USD $5,000</td>
     </tr>
   
    </tbody>
  </table>

  <!-- <p> Teams with the first, second, and third highest mean scores will be awarded.
    Besides, the team with the most innovative submission judged by a panel of Motional experts will be
    awarded.
    Please refer to <a href="https://nuplan-devkit.readthedocs.io/en/latest/competition.html#prizes">the
    prizes and details</a>. </p> -->
  <br>
  <h4><b>Contact</b></h4>
  <p> </p>
  <li> <a href="https://github.com/motional/nuplan-devkit/issues">GitHub issue</a> </li>
  <li> Motional, <code>nuScenes@motional.com</code> </li>
  <li> Slack channel: <code>#nuplan-challenge-2023</code> </li>
  <p></p>
  <br>
  <h4><b>Related Literature</b></h4>
  <p> </p>
  <li> <a href="https://arxiv.org/pdf/2206.03004.pdf"> Driving in Real Life with Inverse Reinforcement Learning </a> </li>
  <li> <a
                    href="https://openaccess.thecvf.com/content/CVPR2022W/Precognition/papers/Hazard_Importance_Is_in_Your_Attention_Agent_Importance_Prediction_for_Autonomous_CVPRW_2022_paper.pdf"> Importance Is in Your Attention: Agent Importance Prediction for Autonomous Driving </a> </li>
  <p></p>
  
  <!--
        <div class="scrollable">
          <table>
            <thead>
              <tr>
                <th>Method</th>
                <th>OLS (main metric)</th>
                <th> $mAP_{LC}$</th>
                <th> $mAP_{TE}$</th>
                <th> $mAP_{LCLC}$ </th>
                <th> $mAP_{LCTE}$</th>
                <th> F-Score</th>
              </tr>
            </thead>
            <tbody>
              <tr>
                <td><a href="#">\</a></td>
                <td>\</td>
                <td>\</td>
                <td>\</td>
                <td>\</td>
                <td>\</td>
                <td>\</td>
              </tr>
              <tr>
                <td>\</td>
                <td>\</td>
                <td>\</td>
                <td><a href="#">\</a></td>
                <td>\</td>
                <td>\</td>
                <td>\</td>
              </tr>
              <tr>
                <td><a href="#">\</a></td>
                <td>\</td>
                <td>\</td>
                <td>\</td>
                <td>\</td>
                <td>\</td>
                <td>\</td>
              </tr>
              <tr>
                <td><a href="#">\</a></td>
                <td>\</td>
                <td>\</td>
                <td>\</td>
                <td>\</td>
                <td>\</td>
                <td>\</td>
              </tr>
            </tbody>
          </table>
        </div> --> 
  
  <!--         <div>
          <div class="wsite-multicol">
            <div class="wsite-multicol-table-wrap" style="margin:0 -15px;">
              <table class="wsite-multicol-table">
                <tbody class="wsite-multicol-tbody">
                  <tr class="wsite-multicol-tr">
                    <td class="wsite-multicol-col" style="width:36.598465473146%; padding:0 15px;">
                      <div>
                        <div class="wsite-image wsite-image-border-none "
                          style="padding-top:10px;padding-bottom:10px;margin-left:0;margin-right:0;text-align:center">
                          <a>
                            <img src="./images/challenge/lane.gif" alt="Picture"
                              style="width:auto;max-width:100%;height:240px;" />
                          </a>
                          <div style="display:block;font-size:90%"></div>
                        </div>
                      </div>
                    </td>
                    <td class="wsite-multicol-col" style="width:73.401534526854%; padding:0 15px;">
                       <div class="paragraph">         <p class="bts" target="_blank" style="font-size: 3em;">nuPlan Planning Challenge</p> 
                      <div class="paragraph"> <a class="bts" target="_blank" style="font-size: 2em; line-height: 1.4">3D
                          Lane Detection</a>
                        <p itemprop="description" style="font-size: 1.2em;">We annotate 3D lane centerlines and include the F-Score for evaluating predicted
                          results of undirected lane centerlines.
                          Furthermore, we define the subtask of 3D lane detection as detecting directed 3D lane
                          centerlines from the given multi-view images covering the whole horizontal FOV.
                        </p>
                    </td>
                  </tr>
                </tbody>
              </table>
            </div>
          </div>
        </div>
        <div>
          <div class="wsite-multicol">
            <div class="wsite-multicol-table-wrap" style="margin:0 -15px;">
              <table class="wsite-multicol-table">
                <tbody class="wsite-multicol-tbody">
                  <tr class="wsite-multicol-tr">
                    <td class="wsite-multicol-col" style="width:36.598465473146%; padding:0 15px;">
                      <div>
                        <div class="wsite-image wsite-image-border-none "
                          style="padding-top:10px;padding-bottom:10px;margin-left:0;margin-right:0;text-align:center">
                          <a>
                            <img src="./images/challenge/traffic_element.gif" alt="Picture"
                              style="width:auto;max-width:100%;height:240px;" />
                          </a>
                          <div style="display:block;font-size:90%"></div>
                        </div>
                      </div>
                    </td>
                    <td class="wsite-multicol-col" style="width:73.401534526854%; padding:0 15px;">
                      <div class="paragraph"> <a class="bts" target="_blank"
                          style="font-size: 2em; line-height: 1.4">Traffic Element Recognition</a>
                        <p itemprop="description" style="font-size: 1.2em;">
                          The attribute represents the semantic meaning of a traffic element, such as the red color of
                          a traffic light.
                          In this subtask, on the given image in the front view, the location of traffic elements
                          (traffic lights and road signs) and their attributes are demanded to be perceived
                          simultaneously.
      
                        </p>
                    </td>
                  </tr>
                </tbody>
              </table>
            </div>
          </div>
        </div>
        <div>
          <div class="wsite-multicol">
            <div class="wsite-multicol-table-wrap" style="margin:0 -15px;">
              <table class="wsite-multicol-table">
                <tbody class="wsite-multicol-tbody">
                  <tr class="wsite-multicol-tr">
                    <td class="wsite-multicol-col" style="width:36.598465473146%; padding:0 15px;">
                      <div>
                        <div class="wsite-image wsite-image-border-none "
                          style="padding-top:10px;padding-bottom:10px;margin-left:0;margin-right:0;text-align:center">
                          <a>
                            <img src="./images/challenge/topology.gif" alt="Picture"
                              style="width:auto;max-width:100%;height:240px;" />
                          </a>
                          <div style="display:block;font-size:90%"></div>
                        </div>
                      </div>
                    </td>
                    <td class="wsite-multicol-col" style="width:73.401534526854%; padding:0 15px;">
                      <div class="paragraph"> <a class="bts" target="_blank"
                          style="font-size: 1em;">
                        Topology Recognition</a>
                        <p itemprop="description" style="font-size: 1.2em;">We first define the task of recognizing
                          topology relationships in the field of autonomous driving.
                          Given multi-view images, the model learns to recognize the topology relationships among lane
                          centerlines and between lane centerlines and traffic elements.
                          In our case, both vertices and edges are unknown for the model.
                          Thus, lane centerlines and traffic elements are needed to be detected first, and then the
                          topology relationships are built.
                        </p>
                    </td>
                  </tr>
                </tbody>
              </table>6
            </div>
          </div>
        </div> --> 
  
  <!-- ################################################################################################ --> 
  
  <!--<h3><b><p class="title" target="_blank" id="Leaderboard" >Leaderboard</p></b></h3>
        The following result is a mirrored version from test server. For latest results, please refer to TODO. <br><br><br>
        <div class="scrollable">
          <table>
            <thead>
              <tr>
                <th>Method</th>
                <th>OLS (main metric)</th>
                <th> $mAP_{LC}$</th>
                <th> $mAP_{TE}$</th>
                <th> $mAP_{LCLC}$ </th>
                <th> $mAP_{LCTE}$</th>
                <th> F-Score</th>
              </tr>
            </thead>
            <tbody>
              <tr>
                <td><a href="#">\</a></td>
                <td>\</td>
                <td>\</td>
                <td>\</td>
                <td>\</td>
                <td>\</td>
                <td>\</td>
              </tr>
              <tr>
                <td>\</td>
                <td>\</td>
                <td>\</td>
                <td><a href="#">\</a></td>
                <td>\</td>
                <td>\</td>
                <td>\</td>
              </tr>
              <tr>
                <td><a href="#">\</a></td>
                <td>\</td>
                <td>\</td>
                <td>\</td>
                <td>\</td>
                <td>\</td>
                <td>\</td>
              </tr>
              <tr>
                <td><a href="#">\</a></td>6############################################################ --> 
  
  <!-- <h3><b>
            <p class="title" target="_blank" id="starter_code" >Starter Code</p>
          </b></h3>
          Coming soon.
        <p>
          To evaluate performances on different aspects of the task, several metrics are adopted:<br>
          1. $mAP_{LC}$ for mAP on directed lane centerlines<br>
          2. $mAP_{TE}$ for mAP on traffic elements<br>
          3. $mAP_{LCLC}$ for mAP on topology among lane centerlines<br>
          4. $mAP_{LCTE}$ for mAP on topology between lane centerlines and traffic elements.
        </p>
6
--> 
  
  <br>
  <br>
  <br>
    </div>
    </div>
    <div class="bg">
  <br>
  <br>
  <br>
  <h3><b class="title" target="_blank" id="rules">General Rules </b></h3>
  <p> Please refer to <a
                    href="https://docs.google.com/document/d/18wEN6XdSW2VpVgSo0hHEKPN6KPptqvOUv5Znc2_lB3o/edit?usp=sharing">rules</a>. </p>
  <br>
  <br>
  <br>
  <hr>
  <br>
  <br>
  <br>
  <h3><b class="title" target="_blank" id="FAQ">FAQ</b></h3>
  <div class="accordion-body">
    <div class="accordion"> 
      <!-- <h1>Frequently Asked Questions</h1>  -->
      
      <hr>
      <div class="container">
        <div class="label"><b>How do we/I download the data?</b></div>
        <div class="content">For each track, we provide links for downloading data in the GitHub
          repository.
          The repository, which might also contain dataset API, baseline model, and other helpful
          information, is a good start to begin your participation. </div>
      </div>
      <hr>
      <div class="container">
        <div class="label"><b>How many times can we/I make a submission?</b></div>
        <div class="content"> Each track has its submission limit. Please refer to the EvalAI for each track.
          Submissions that error out do not count against this limit. </div>
      </div>
      <hr>
      <div class="container">
        <div class="label"><b>How many tracks can we/I take part in?</b></div>
        <div class="content"> A team can participate in multiple tracks.
          An entity cannot be affiliated with more than one team unless the entity is an academic
          entity (e.g., a university). </div>
      </div>
    </div>
  </div>
  <hr>
  <div class="wrapper row3">
    <div class="map">
      <iframe src="map.html" frameborder="0"></iframe>
    </div>
  </div>
  <div class="clear"></div>
</div>


  
     
<footer class="footer"  > 
  <div class="footer_t">
    <h6>OpenDriveLab</h6>
    <nav>
      <ul class="nospace inline pushright uppercase">
        <!-- <li><a  href="index.html"><i class="tb icon_home"></i></a></li> -->
        <li><a  href="https://opendrivelab.com"><i class="tb icon_home"></i></a></li>
      </ul>
    </nav>
  </div>

<div class="copyright" >
  <p>Copyright © 2023 - All Rights Reserved - <a style="color:#D68910;" href="http://opendrivelab.com/">OpenDriveLab at Shanghai AI Lab</a>
  </p>
</div>
</footer>
<script src="style/js/jquery-3.1.1.min.js" type="text/javascript" charset="utf-8"></script> 
<script src="style/js/all.js" type="text/javascript" charset="utf-8"></script> 
 
</body>
</html>
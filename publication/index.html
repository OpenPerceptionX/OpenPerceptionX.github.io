<!DOCTYPE html>
<!--
Template Name: Besloor
Author: <a href="https://www.os-templates.com/">OS Templates</a>
Author URI: https://www.os-templates.com/
Copyright: OS-Templates.com
Licence: Free to use under our free template licence terms
Licence URI: https://www.os-templates.com/template-terms
-->
<html lang="">
<!-- To declare your language - read more here: https://www.w3.org/International/questions/qa-html-language-declarations -->

<head>
  <title> Publication | OpenDriveLab 浦驾开放平台</title>

  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no">
  <link href="../layout/styles/layout.css" rel="stylesheet" type="text/css" media="all">
</head>

<!-- <style>*{-webkit-box-sizing:border-box;-moz-box-sizing:border-box;box-sizing:border-box}html{font-family:-apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, "Helvetica Neue", Arial, "Noto Sans", sans-serif;font-size:16px;line-height:1.5}body{padding:1.5rem 1.5rem 3rem;margin:0;font-size:1rem;color:#333;background-color:#fff}iframe{overflow:hidden;border:0}h1,h2{margin-top:0;line-height:1;text-rendering:optimizelegibility}h1{margin-bottom:.5rem;font-size:3rem}h2{margin-top:2rem;margin-bottom:1rem}h3{margin-top:2rem;margin-bottom:.5rem}p{margin-top:0;margin-bottom:1rem}h1+p{font-size:1.25rem;color:#555}a{color:#0366d6;text-decoration:none}a:hover{text-decoration:underline}table{width:100%;border-collapse:collapse}th,td{padding:.5rem;font-size:90%;vertical-align:top;border:1px solid #eee}th{background-color:#f5f5f5}.deprecated{display:inline-block;padding:.25rem .5rem;font-size:75%;font-weight:700;line-height:1.6;color:#fff;background-color:#e5271c;border-radius:.2rem}code,pre{font-family:Menlo, "Courier New", monospace;font-size:95%}code{padding:2px 4px;font-size:85%;color:#d53049;background-color:#f7f7f9;border-radius:.2rem}pre{display:block;margin:0 0 1rem;line-height:1.4;white-space:pre;white-space:pre-wrap}pre code{padding:0;color:inherit;background-color:transparent;border:0}.highlight{padding:1rem;margin:0 0 1rem;background-color:#f7f7f9}.highlight pre{margin-bottom:0;word-wrap:break-word}.highlight+.highlight{margin-top:1rem}.btn{display:inline-block;padding:.5rem 1.25rem;font-weight:700;color:#fff;text-decoration:none;background-color:#0366d6;border:1px solid #0366d6;border-radius:6px}.btn:hover{text-decoration:none;background-color:#005cc5}.btn:active{border-color:#005cc5;box-shadow:inset 0 5px 10px rgba(0,0,0,0.2)}.tweet-button{height:30px;overflow:hidden}.tweet-button+p{margin-top:1rem;color:#767676}.container{max-width:40rem;margin-right:auto;margin-left:auto}hr{display:block;width:7rem;height:1px;margin:2.5rem 0;background-color:#eee;border:0}.example{margin-bottom:1rem;overflow:auto}.example iframe{display:block}.example iframe+iframe{margin-top:1rem}@media (min-width: 34em){.example{display:inline-block;line-height:30px}.example iframe{float:left}.example iframe+iframe{margin-top:5px;margin-left:1rem}}#markdown-toc li{margin-bottom:.25rem}.hll{background-color:#ffc}.c{color:#727272}.k{color:#069}.o{color:#555}.cm{color:#727272}.cp{color:#008085}.c1{color:#727272}.cs{color:#727272}.gd{background-color:#fcc;border:1px solid #c00}.ge{font-style:italic}.gr{color:#f00}.gh{color:#030}.gi{background-color:#cfc;border:1px solid #0c0}.go{color:#aaa}.gp{color:#009}.gu{color:#030}.gt{color:#9c6}.kc{color:#069}.kd{color:#069}.kn{color:#069}.kp{color:#069}.kr{color:#069}.kt{color:#078}.m{color:#bc511f}.s{color:#d82d36}.na{color:#006ee0}.nb{color:#366}.nc{color:#168174}.no{color:#360}.nd{color:#685fe3}.ni{color:#727272}.ne{color:#c00}.nf{color:#b715f4}.nl{color:#685fe3}.nn{color:#007ca5}.nt{color:#2f6f9f}.nv{color:#033}.ow{color:#000}.w{color:#bbb}.mf{color:#bc511f}.mh{color:#bc511f}.mi{color:#bc511f}.mo{color:#bc511f}.sb{color:#c30}.sc{color:#c30}.sd{font-style:italic;color:#c30}.s2{color:#c30}.se{color:#c30}.sh{color:#c30}.si{color:#a00}.sx{color:#c30}.sr{color:#337e7e}.s1{color:#c30}.ss{color:#fc3}.bp{color:#366}.vc{color:#033}.vg{color:#033}.vi{color:#033}.il{color:#bc511f}
</style> -->

<body id="top">
  <!-- ################################################################################################ -->
  <!-- ################################################################################################ -->
  <!-- ################################################################################################ -->
  <!-- Top Background Image Wrapper -->
  <div class="bgded overlay " style="background-image:url('../images/gallery/stage-publications.jpeg');">


    <!-- ################################################################################################ -->
    <div class="wrapper row0">
      <div id="topbar" class="hoc clear">
        <!-- ################################################################################################ -->
        <div class="fl_left">
          <!-- ################################################################################################ -->
          <ul class="nospace"></ul>
          <!-- ################################################################################################ -->
        </div>
        <div class="fl_right">
          <!-- ################################################################################################ -->
          <ul class="nospace"></ul>
          <!-- ################################################################################################ -->
        </div>
        <!-- ################################################################################################ -->
      </div>
    </div>
    <!-- ################################################################################################ -->
    <!-- ################################################################################################ -->
    <!-- ################################################################################################ -->
    <div class="wrapper row1">
      <header id="header" class="hoc clear">
        <!-- ################################################################################################ -->
        <div id="logo" class="fl_left">
          <h1>OpenDriveLab | 浦驾自动驾驶开放平台</h1>
        </div>
        <!-- ################################################################################################ -->
        <nav id="mainav" class="fl_right">
          <ul class="clear">
            <li><a href="../index.html">Home</a></li>

            <li><a href="../event/index.html" class="drop">Event</a>
              <ul>
                <li><a href="../sr4ad/iclr23.html">ICLR 2023 Workshop</a></li>
                <li><a href="../e2ead/cvpr23.html">CVPR 2023 Workshop</a></li>

              </ul>
            </li>
<!--             <li><a target="_blank" href="https://www.zhihu.com/people/PerceptionX/posts">Blog In Chinese <i
                  class="fas fa-external-link-square-alt"></i></a>
            </li> -->
            <li class="active"><a href="../publication/index.html">Publication</a></li>
          </ul>
        </nav>
        <!-- ################################################################################################ -->
      </header>
    </div>
    <!-- ################################################################################################ -->
    <!-- ################################################################################################ -->
    <!-- ################################################################################################ -->

    <div id="breadcrumb" class="hoc clear">
      <!-- ################################################################################################ -->
      <h2 class="heading">Publications</h2>
      <!-- ################################################################################################ -->
    </div>
  </div>

  <div class="wrapper row3">
    <main class="hoc container clear">
      <!-- main body -->
      <ul class="nospace group overview btmspace-80">
        <div class="sidebar one_quarter first">
          <!-- ################################################################################################ -->
          <h6> </h6>
          <nav class="sdb_holder">
            <ul>
              <h6>Publications</h6>
              <li><a href="#Selected Publications">Editor's Pick</a></li>
              <li><a href="#Autonomous Driving">End-to-end Autonomous Driving</a></li>
              <li><a href="#BEVPerception">Bird's-eye-view Perception</a></li>
              <li><a href="#pp">Prediction and Planning</a></li>
              <li><a href="#cv-at-large">Computer Vision at Large</a>
            </ul>
          </nav>

        </div>
        <!-- ################################################################################################ -->

        <div class="content three_quarter">

          <article>

            <!-- ################################################################################################ -->
            <p> <topic>
            We claim OpenDriveLab as one of the most top research team around the globe, 
            since we got talented people and publish work at top venues only.
          </topic>
            </p>

            <h3><b><p class="btb" target="_blank" id="Selected Publications">Editor's Pick</p></b></h3><br>

            <table>
              <tr>
                <td class="wsite-multicol-col-left" >
                    <div class="wsite-image"style="padding-top:10px">
                      <a><img src="../images/pub/Delving.png" alt="Picture"/></a>
                    </div>
                </td>
                <td class="wsite-multicol-col-right" style="padding: 0px 15px;">
                  <div>
                    <p class="medium"><b>Delving into the Devils of Bird's-Eye-View Perception: A
                        Review, Evaluation and Recipe</b></p>
                    <p class="bts" target="_blank"> Hongyang Li, <a href="https://scholar.google.com/citations?user=dgYJ6esAAAAJ&hl=en" style="color:blue">Chonghao Sima</a>, Jifeng Dai, Wenhai Wang, Lewei Lu, <em>et al.</em> <br>
                      <a href="https://arxiv.org/abs/2209.05324">arXiv 2022</a> 
                      <iframe style="margin-left: 2px; margin-bottom:-5px;" frameborder="0" scrolling="0"
                        width="91px" height="20px"
                        src="https://ghbtns.com/github-btn.html?user=openperceptionx&repo=bevperception-survey-recipe&type=star&count=true">
                      </iframe> <code>[Setup the Table]</code>
                      <br>
                      <a style="color: gray;font-style:italic;">We review the most recent work on BEV perception and provide analysis of different solutions.</a>
                    </p>
                  </div>
                </td>
              </tr>
              

              <tr>
                <td class="wsite-multicol-col-left" >
                  <div class="wsite-image" style="padding-top:30px">
                      <a><img src="../images/pub/bevf1.png" alt="Picture"></a>
                    </div>
                </td>
                <td class="wsite-multicol-col-right" style="padding: 0px 15px;">
                  <div>
                    <p class="medium"><b>BEVFormer: Learning Bird's-Eye-View Representation from Multi-Camera Images via Spatiotemporal Transformers</b></p>
                    <p class="bts" target="_blank">Zhiqi Li, Wenhai Wang, Hongyang Li, Enze Xie, Chonghao Sima, <em>et al.</em>
                      <br> <a href="https://arxiv.org/abs/2203.17270">ECCV 2022</a> 

                      <iframe style="margin-left: 2px; margin-bottom:-5px;" frameborder="0" scrolling="0" width="100px" height="20px"
                        src="https://ghbtns.com/github-btn.html?user=fundamentalvision&repo=BEVFormer&type=star&count=true">
                      </iframe>
                      <code>[Baseline][nuScenes First Place]
                        <br>[Waymo Challenge 2022 Official First Place]</code>
                      <br>
                      <a style="color: gray;font-style:italic;">A paradigm for autonomous driving that applies both Transformer and Temporal structure to generate BEV features.</a>
                    </p>
                  </div>
                </td>
              </tr>


              <tr>
                <td class="wsite-multicol-col-left" >
                  <div class="wsite-image" style="padding-top:30px">
                      <a><img src="../images/pub/persfor.png" alt="Picture"></a>
                    </div>
                </td>
                <td class="wsite-multicol-col-right" style="padding: 0px 15px;">
                  <div>
                    <p class="medium"><b>PersFormer: 3D Lane Detection via Perspective Transformer and the OpenLane Benchmark</b></p>
                    <p class="bts" target="_blank"> <a href="https://scholar.google.com/citations?user=ulZxvY0AAAAJ&hl=en" style="color:blue">Li Chen</a>, Chonghao Sima, Yang Li, Xiangwei Geng, Junchi Yan, <em>et al.</em>
                      <br>
                      <a href="https://arxiv.org/abs/2203.11089">ECCV 2022 (Oral)</a>

                      <iframe style="margin-left: 2px; margin-bottom:-5px;" frameborder="0" scrolling="0"
                        width="91px" height="20px"
                        src="https://ghbtns.com/github-btn.html?user=OpenDriveLab&repo=OpenLane&type=star&count=true">
                      </iframe>
                      <iframe style="margin-left: 2px; margin-bottom:-5px;" frameborder="0" scrolling="0"
                        width="91px" height="20px"
                        src="https://ghbtns.com/github-btn.html?user=OpenPerceptionX&repo=PersFormer_3DLane&type=star&count=true">
                      </iframe>
                      
                      <code>[Redefine the Community]</code>
                      <br><a style="color: gray;font-style:italic;">PersFormer adopts a unified 2D/3D anchor design and an auxiliary task to detect 2D/3D lanes; we release one of the first large-scale real-world 3D lane datasets, OpenLane. </a>
                    </p>
                  </div>
                </td>
              </tr>

            </table>

            <br><br>
            <!-- #####14########################################################################################### -->

            <h3><b><p class="btb" target="_blank" id="Autonomous Driving">End-to-end Autonomous Driving</p></b></h3>
            <table>
              <tr>
                <td class="wsite-multicol-col-left" >
                    <div class="wsite-image" style="padding-top:20px">
                      <a><img src="../images/pub/Policy.png" alt="Picture"/></a>
                    </div>
                </td>
                <td class="wsite-multicol-col-right" style="padding: 0px 15px;">
                  <div>
                    <p class="medium"><b>Policy Pre-Training for End-to-End Autonomous Driving via Self-Supervised Geometric Modeling</b></p>
                    <p class="bts" target="_blank"> 
                      <a href="https://scholar.google.com/citations?user=9mssd5EAAAAJ&hl=en" style="color:blue">Penghao Wu</a>, Li Chen, Hongyang Li, Xiaosong Jia, Junchi Yan, Yu Qiao<br>
                      <a href="https://arxiv.org/abs/2301.01006">ICLR 2023</a>
                        <iframe style="margin-left: 2px; margin-bottom:-5px;" frameborder="0" scrolling="0"
                          width="91px" height="20px"
                          src="https://ghbtns.com/github-btn.html?user=opendrivelab&repo=ppgeo&type=star&count=true">
                        </iframe>
                        <br><a style="color: gray;font-style:italic;"> An intuitive and straightforward fully self-supervised framework curated for the policy pre-training in visuomotor driving. </a>
                    </p>
                  </div>
                </td>
              </tr>
              

              <tr>
                <td class="wsite-multicol-col-left" >
                  <div class="wsite-image" style="padding-top:20px">
                      <a><img src="../images/pub/traj.png" alt="Picture"></a>
                    </div>
                </td>
                <td class="wsite-multicol-col-right" style="padding: 0px 15px;">
                  <div>
                    <p class="medium"><b>Trajectory-guided Control Prediction for End-to-end Autonomous Driving: A Simple yet Strong Baseline</b></p>
                    <p class="bts" target="_blank">Penghao Wu, Xiaosong Jia, Li Chen, Junchi Yan, Hongyang Li, Yu Qiao 
                      <br>
                    <a href="https://arxiv.org/abs/2206.08129">NeurIPS 2022</a>
                    <iframe
                    style="margin-left: 2px; margin-bottom:-5px;"
                    frameborder="0" scrolling="0" width="91px" height="20px"
                    src="https://ghbtns.com/github-btn.html?user=OpenPerceptionX&repo=TCP&type=star&count=true" >
                   </iframe> <code>[Carla First Place]</code>
                    <br><a style="color: gray;font-style:italic;">Take the initiative to explore the combination of controller based on a planned trajectory and perform control prediction. </a>
                  </p>
                  </div>
                </td>
              </tr>


              <tr>
                <td class="wsite-multicol-col-left" >
                  <div class="wsite-image" style="padding-top:20px">
                      <a><img src="../images/pub/stp3.png" alt="Picture"></a>
                    </div>
                </td>
                <td class="wsite-multicol-col-right" style="padding: 0px 15px;">
                  <div>
                    <p class="medium"><b>ST-P3: End-to-end Vision-based Autonomous Driving via Spatial-Temporal Feature Learning</b></p>
                    <p class="bts" target="_blank">Shengchao Hu, Li Chen, Penghao Wu, Hongyang Li, Junchi Yan, Dacheng Tao 
                      <br>
                    <a href="https://arxiv.org/abs/2207.07601">ECCV 2022</a>
                    <iframe style="margin-left: 2px; margin-bottom:-5px;"
                    frameborder="0" scrolling="0" width="91px" height="20px"
                    src="https://ghbtns.com/github-btn.html?user=openperceptionx&repo=st-p3&type=star&count=true" >
                   </iframe>
                    <br><a style="color: gray;font-style:italic;">A spatial-temporal feature learning scheme towards a set of more representative features for perception, prediction and planning tasks simultaneously. </a>
                  </p>
                  </div>
                </td>
              </tr>

            </table>


            <br><br>
            <!-- #####14########################################################################################### -->

            <h3><b><p class="btb" target="_blank" id="BEVPerception">Bird's-eye-view Perception</p></b></h3>
            <table>
              <tr>
                <td class="wsite-multicol-col-left" >
                    <div class="wsite-image" style="padding-top:10px">
                      <a><img src="../images/pub/goal.png" alt="Picture"/></a>
                    </div>
                </td>
                <td class="wsite-multicol-col-right" style="padding: 0px 15px;">
                  <div>
                    <p class="medium"><b>Goal-Oriented Autonomous Driving</b></p>
                    <p class="bts" target="_blank">Yihan Hu, Jiazhi Yang, Li Chen, Keyu Li, Chonghao Sima, Hongyang Li,  <em>et al.</em><br>
                      <a href="https://arxiv.org/abs/2212.10156">arXiv 2022 </a>
                      <iframe style="margin-left: 2px; margin-bottom:-5px;" frameborder="0" scrolling="0"
                        width="91px" height="20px"
                        src="https://ghbtns.com/github-btn.html?user=OpenDriveLab&repo=UniAD&type=star&count=true">
                      </iframe> <code>[Sell a New Philosophy]</code>
                      <br><a style="color: gray;font-style:italic;">A comprehensive framework up-to-date that incorporates full-stack driving tasks in one network. </a>
                    </p>
                  </div>
                </td>
              </tr>
              

              <tr>
                <td class="wsite-multicol-col-left" >
                  <div class="wsite-image" style="padding-top:25px">
                      <a><img src="../images/pub/befv2.png" alt="Picture"></a>
                    </div>
                </td>
                <td class="wsite-multicol-col-right" style="padding: 0px 15px;">
                  <div>
                    <p class="medium"><b>BEVFormer v2: Adapting Modern Image Backbones to Bird's-Eye-View Recognition via Perspective Supervision</b></p>
                    <p class="bts" target="_blank">Chenyu Yang, Yuntao Chen, Hao Tian, Chenxin Tao, Xizhou Zhu, Zhaoxiang Zhang, Gao Huang, Hongyang Li, Yu Qiao, Lewei Lu, Jie Zhou, Jifeng Dai<br>
                      <a href="https://arxiv.org/abs/2211.10439">arXiv 2022 </a>
                      <br><a style="color: gray;font-style:italic;">A novel bird's-eye-view (BEV) detector with perspective supervision, which converges faster and better suits modern image backbones. </a>
                    </p>
                  </div>
                </td>
              </tr>

            </table>


      <br><br>
            <!-- #####14########################################################################################### -->


            <h3><b><p class="btb" target="_blank" id="pp">Prediction and Planning</p></b></h3>

            <table>
              <tr>
                <td class="wsite-multicol-col-left" >
                    <div class="wsite-image" style="padding-top:30px">
                      <a><img src="../images/pub/towards.png" alt="Picture"/></a>
                    </div>
                </td>
                <td class="wsite-multicol-col-right" style="padding: 0px 15px;">
                  <div>
                    <p class="medium"><b>Towards Capturing the Temporal Dynamics for Trajectory Prediction: a Coarse-to-Fine Approach</b></p>
                    <p class="bts" target="_blank">Xiaosong Jia, Li Chen, Penghao Wu, Jia Zeng, Junchi Yan, Hongyang Li, Yu Qiao<br>
                      <a href="https://openreview.net/forum?id=PZiKO7mjC43">CoRL 2022 </a>

                      <br><a style="color: gray;font-style:italic;">We find taking scratch trajectories generated by MLP as input, a refinement module based on structures with temporal prior  could  boost the accuracy. </a>
                    </p>
                  </div>
                </td>
              </tr>
              

              <tr>
                <td class="wsite-multicol-col-left" >
                  <div class="wsite-image" style="padding-top:00px">
                      <a><img src="../images/pub/hdgt-2.jpg" alt="Picture"></a>
                    </div>
                </td>
                <td class="wsite-multicol-col-right" style="padding: 0px 15px;">
                  <div>
                    <p class="medium"><b>HDGT: Heterogeneous driving graph transformer for multi-agent trajectory prediction via scene encoding</b></p>
                    <p class="bts" target="_blank">Xiaosong Jia, Penghao Wu, Li Chen, Hongyang Li, Yu Liu, Junchi Yan<br>
                      <a href="https://arxiv.org/abs/2205.09753">arXiv 2022 </a>
                      <iframe style="margin-left: 2px; margin-bottom:-5px;" frameborder="0" scrolling="0"
                        width="91px" height="20px"
                        src="https://ghbtns.com/github-btn.html?user=OpenPerceptionX&repo=HDGT&type=star&count=true">
                      </iframe>
                      <br><a style="color: gray;font-style:italic;"> HDGT models the driving scene as a heterogeneous graph with different types of nodes and edges.
                      </a>
                    </p>
                  </div>
                </td>
              </tr>

            </table>



      <br><br>
            <!-- #####14########################################################################################### -->

            <h3><b><p class="btb" target="_blank" id="cv-at-large">Computer Vision at Large</p></b></h3>


            <table>
              <tr>
                <td class="wsite-multicol-col-left" >
                    <div class="wsite-image" style="padding-top:20px">
                      <a><img src="../images/pub/stare.png" alt="Picture"/></a>
                    </div>
                </td>
                <td class="wsite-multicol-col-right" style="padding: 0px 15px;">
                  <div>
                    <p class="medium"><b>Stare at What You See: Masked Image Modeling without Reconstruction</b></p>
                    <p class="bts" target="_blank">Hongwei Xue, Peng Gao, Hongyang Li, Yu Qiao, Hao Sun, Houqiang Li, Jiebo Luo</em><br>
                      <a href="https://arxiv.org/abs/2211.08887">arXiv 2022 </a>
                      <iframe
                        style="margin-left: 2px; margin-bottom:-5px;"
                        frameborder="0" scrolling="0" width="91px" height="20px"
                        src="https://ghbtns.com/github-btn.html?user=OpenPerceptionX&repo=maskalign&type=star&count=true" >
                      </iframe>
                      <!-- <code>[Sell a New Philosophy]</code> -->
                      <br><a style="color: gray;font-style:italic;">
                        An efficient MIM paradigm MaskAlign and a Dynamic Alignment module to apply learnable alignment to tackle the problem of input inconsistency. </a>
                    </p>
                  </div>
                </td>
              </tr>
              

            </table>



      <!-- ################################################################################################ -->
      <!-- ################################################################################################ -->
        
          </article>
        </div> 
      </ul>

      <!-- ################################################################################################ -->


    </main>
  </div>



  <div class="wrapper row4">
    <footer id="footer" class="hoc clear">
      <!-- ################################################################################################ -->
      <div class="center btmspace-80">
        <div class="four_quarter">

          <h6 class="heading">OpenDriveLab</h6>
          <nav>
            <ul class="nospace inline pushright uppercase">
              <li><a href="../index.html"><i class="fas fa-lg fa-home"></i></a></li>

            </ul>
          </nav>
        </div>
      </div>
      <!-- ################################################################################################ -->
    </footer>
  </div>
  <!-- ################################################################################################ -->
  <!-- ################################################################################################ -->
  <!-- ################################################################################################ -->
  <div class="wrapper row5">
    <div id="copyright" class="hoc clear">
      <!-- ################################################################################################ -->
      <p class="fl_left">Copyright &copy; 2023 - All Rights Reserved - OpenDriveLab</p>

      <!-- ################################################################################################ -->
    </div>
  </div>
  <!-- ################################################################################################ -->
  <!-- ################################################################## ############################## -->
  <!-- ################################################################################################ -->
  <a id="backtotop" href="#top"><i class="fas fa-chevron-up"></i></a>
  <!-- JAVASCRIPTS -->
  <script src="../layout/scripts/jquery.min.js"></script>
  <script src="../layout/scripts/jquery.backtotop.js"></script>
  <script src="../layout/scripts/jquery.mobilemenu.js"></script>
</body>

</html>
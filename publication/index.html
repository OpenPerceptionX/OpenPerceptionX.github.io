<!DOCTYPE html>
<!--
Template Name: Besloor
Author: <a href="https://www.os-templates.com/">OS Templates</a>
Author URI: https://www.os-templates.com/
Copyright: OS-Templates.com
Licence: Free to use under our free template licence terms
Licence URI: https://www.os-templates.com/template-terms
-->
<html lang="">
<!-- To declare your language - read more here: https://www.w3.org/International/questions/qa-html-language-declarations -->
<head>
<title> Publication | OpenDriveLab 浦驾开放平台</title>

<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no">
<link href="../layout/styles/layout.css" rel="stylesheet" type="text/css" media="all">
</head>
<body id="top">
<!-- ################################################################################################ -->
<!-- ################################################################################################ -->
<!-- ################################################################################################ -->
<!-- Top Background Image Wrapper -->
<div class="bgded overlay" style="background-image:url('../images/gallery/stage-publications.jpeg');"> 
  <!-- ################################################################################################ -->
  <div class="wrapper row0">
    <div id="topbar" class="hoc clear"> 
      <!-- ################################################################################################ -->
      <div class="fl_left"> 
        <!-- ################################################################################################ -->
        <ul class="nospace">
<!--           <li><i class="fas fa-phone"></i> +00 (123) 456 7890</li>
          <li><i class="far fa-envelope"></i> info@domain.com</li> -->
        </ul>
        <!-- ################################################################################################ -->
      </div>
      <div class="fl_right"> 
        <!-- ################################################################################################ -->
        <ul class="nospace">
<!--           <li><a href="index.html"><i class="fas fa-home"></i></a></li>
          <li><a href="#" title="Help Centre"><i class="fas fa-life-ring"></i></a></li>
          <li><a href="#" title="Login"><i class="fas fa-sign-in-alt"></i></a></li>
          <li><a href="#" title="Sign Up"><i class="fas fa-edit"></i></a></li> -->
        </ul>
        <!-- ################################################################################################ -->
      </div>
      <!-- ################################################################################################ -->
    </div>
  </div>
  <!-- ################################################################################################ -->
  <!-- ################################################################################################ -->
  <!-- ################################################################################################ -->
  <div class="wrapper row1">
    <header id="header" class="hoc clear"> 
      <!-- ################################################################################################ -->
      <div id="logo" class="fl_left">
        <h1>OpenDriveLab | 浦驾自动驾驶开放平台</h1>
      </div>
      <!-- ################################################################################################ -->
      <nav id="mainav" class="fl_right">
        <ul class="clear">
          <li><a href="../index.html">Home</a></li>
          <li><a class="drop" href="../research/index.html">Research</a>
          	 <ul>
              <li><a href="../research/bev.html">BEV Perception</a></li>
              <li><a href="../research/e2e.html">End-to-end Autonomous Driving</a></li>
              <li><a href="../research/openlane.html">OpenLane</a></li>
            </ul>
          </li>
          <li><a class="drop">Event</a>
            <ul>
              <li><a href="../event/iclr23_ADworkshop.html">ICLR 2023 Workshop</a></li>
              <li><a class="drop">Past Events</a>
                <ul>
                  <li><a href="https://zhuanlan.zhihu.com/p/573144047">PRCV 2022 自动驾驶专业论坛（主办）</a></li>
                  <li><a href="https://docs.google.com/presentation/d/1DBJ417-31FPvodk4mK5BG_2NNL6nHW3jR8IMFJZlJpI/edit?usp=sharing">VALSE 2022 专业论坛报告</a></li>
                  <li><a href="https://docs.google.com/presentation/d/1cfBy_1X10AQOx0NbF6izfqJkhViTVGlQ3JcQ9wokrfo/edit?usp=sharing">ECCV 2022 Workshop Talk </a></li>
                </ul>
              </li>    
            </ul>
          </li>
          <li><a target="_blank" href="https://www.zhihu.com/people/PerceptionX/posts">Blog <i class="fas fa-external-link-square-alt"></i></a></li>
          <li class="active"><a href="../publication/index.html">Publication</a></li>
        </ul>
      </nav>
      <!-- ################################################################################################ -->
    </header>
  </div>
  <!-- ################################################################################################ -->
  <!-- ################################################################################################ -->
  <!-- ################################################################################################ -->
  
  <div id="breadcrumb" class="hoc clear"> 
    <!-- ################################################################################################ -->
    <h2 class="heading">Publications</h2>
    <!-- ################################################################################################ -->
  </div>

<div class="wrapper row3">
  <main class="hoc container clear"> 
    <!-- main body -->
    <ul class="nospace group overview btmspace-80">
      <li class="four_quarter">
        <article>

          <!-- <a href="#"><i class="fas fa-eraser"></i></a> -->
          <p class="bts" target="_blank" >17. Penghao Wu, Li Chen, Hongyang Li, Xiaosong Jia, Junchi Yan, Yu Qiao; ‘Policy Pre-Training for End-to-End Autonomous Driving via Self-Supervised Geometric Modeling’ (arXiv, 2023) 
            <a href="https://doi.org/10.48550/arXiv.2301.01006" style="color: #0040ff;">[Paper]</a>
            <a href="https://github.com/opendrivelab/ppgeo" style="color: #FF0000;">[Code]</a></p>


          <p class="bts" target="_blank" >16. Yihan Hu, Jiazhi Yang, Li Chen, Keyu Li, Chonghao Sima, Xizhou Zhu, Siqi Chai, Senyao Du, Tianwei Lin, Wenhai Wang, Lewei Lu, Xiaosong Jia, Qiang Liu, Jifeng Dai, Yu Qiao, Hongyang Li; ‘Goal-Oriented Autonomous Driving’ (arXiv, 2022)           
            <body>
            <a href="https://doi.org/10.48550/arXiv.2212.10156" style="color: #0040ff;">[Paper]</a>
          </body>
          <body>
            <a href="https://github.com/OpenDriveLab/UniAD" style="color: #FF0000;">[Code]</a>
          </body></p>



          <p class="bts" target="_blank" >15. Chenyu Yang, Yuntao Chen, Hao Tian, Chenxin Tao, Xizhou Zhu, Zhaoxiang Zhang, Gao Huang, Hongyang Li, Yu Qiao, Lewei Lu, Jie Zhou, Jifeng Dai; ‘BEVFormer v2: Adapting Modern Image Backbones to Bird’s-Eye-View Recognition via Perspective Supervision’ (arXiv, 2022)  <body>
            <a href="https://doi.org/10.48550/arXiv.2211.10439" style="color: #0040ff;">[Paper]</a>
          </body>
          <body>
            <a href="https://github.com/fundamentalvision/BEVFormer" style="color: #FF0000;">[Code]</a>
          </body></p>


          <p class="bts" target="_blank" >14. Hongwei Xue, Peng Gao, Hongyang Li, Yu Qiao, Hao Sun, Houqiang Li, Jiebo Luo; ‘Stare at What You See: Masked Image Modeling without Reconstruction’ (arXiv, 2022)  <body>
            <a href="https://doi.org/10.48550/arXiv.2211.08887" style="color: #0040ff;">[Paper]</a>
          </body>
          <body>
            <a href="https://github.com/OpenPerceptionX/maskalign" style="color: #FF0000;">[Code]</a>
          </body></p>


          <p class="bts" target="_blank" >13. Hongyang Li, Chonghao Sima, Jifeng Dai, Wenhai Wang, Lewei Lu, Huijie Wang, Enze Xie, Zhiqi Li, Hanming Deng, Hao Tian, Xizhou Zhu, Li Chen, Yulu Gao, Xiangwei Geng, Jia Zeng, Yang Li, Jiazhi Yang, Xiaosong Jia, Bohan Yu, Yu Qiao, Dahua Lin, Si Liu, Junchi Yan, Jianping Shi, Ping Luo; ‘Delving into the Devils of Bird’s-Eye-View Perception: A Review, Evaluation and Recipe’ (arXiv, 2022) <body>
            <a href="https://doi.org/10.48550/arXiv.2209.05324" style="color: #0040ff;">[Paper]</a>
          </body>
          <body>
            <a href="https://github.com/openperceptionx/bevperception-survey-recipe" style="color: #FF0000;">[Code]</a>
          </body></p>


          <p class="bts" target="_blank" >12. Xiaosong Jia, Li Chen, Penghao Wu, Jia Zeng, Junchi Yan, Hongyang Li, Yu Qiao; ‘Towards Capturing the Temporal Dynamics for Trajectory Prediction: A Coarse-to-Fine Approach’ <b>Coference on Robot Learning (CoRL)</b>
            <body>
            <a href="https://scholar.google.com/citations?view_op=view_citation&hl=zh-CN&user=Hfrih1EAAAAJ&sortby=pubdate&citation_for_view=Hfrih1EAAAAJ:VaXvl8Fpj5cC" style="color: #0040ff;">[Paper]</a>
          </body></p>


          <p class="bts" target="_blank" >11. Shengchao Hu, Li Chen, Penghao Wu, Hongyang Li, Junchi Yan, Dacheng Tao; ‘ST-P3: End-to-End Vision-Based Autonomous Driving via Spatial-Temporal Feature Learning’  <b>ECCV 2022</b>  <body>
            <a href="https://doi.org/10.48550/arXiv.2207.07601" style="color: #0040ff;">[Paper]</a>
          </body>
          <body>
            <a href="https://github.com/openperceptionx/st-p3" style="color: #FF0000;">[Code]</a>
          </body></p>


          <p class="bts" target="_blank" >10. Li Chen, Tutian Tang, Zhitian Cai, Yang Li, Penghao Wu, Hongyang Li, Jianping Shi, Junchi Yan, Yu Qiao; ‘Level 2 Autonomous Driving on a Single Device: Diving into the Devils of Openpilot’ (arXiv, 2022)  <body>
            <a href="https://doi.org/10.48550/arXiv.2206.08176" style="color: #0040ff;">[Paper]</a>
          </body>
          <body>
            <a href="https://github.com/openperceptionx/openpilot-deepdive" style="color: #FF0000;">[Code]</a>
          </body></p>




          <p class="bts" target="_blank" >9. Penghao Wu, Xiaosong Jia, Li Chen, Junchi Yan, Hongyang Li, Yu Qiao; ‘Trajectory-Guided Control Prediction for End-to-End Autonomous Driving: A Simple yet Strong Baseline’   <b>NeurIPS 2022</b>  <body>
            <a href="https://doi.org/10.48550/arXiv.2206.08129" style="color: #0040ff;">[Paper]</a>
          </body>
          <body>
            <a href="https://github.com/OpenPerceptionX/TCP" style="color: #FF0000;">[Code]</a>
          </body></p>




          <p class="bts" target="_blank" >8. Hongyang Li, Yu Liu, Wanli Ouyang, Xiaogang Wang; ‘Method and Apparatus for Detecting Object, Method and Apparatus for Training Neural Network, and Electronic Device’, 2022 <body>
            <a href="https://patents.google.com/patent/US11321593B2/en" style="color: #0040ff;">[Paper]</a>
          </body></p>




          <p class="bts" target="_blank" >7. Xiaosong Jia, Penghao Wu, Li Chen, Hongyang Li, Yu Liu, Junchi Yan; ‘HDGT: Heterogeneous Driving Graph Transformer for Multi-Agent Trajectory Prediction via Scene Encoding’ (arXiv, 2022) <body>
            <a href="https://doi.org/10.48550/arXiv.2205.09753" style="color: #0040ff;">[Paper]</a>
          </body></p>




          <p class="bts" target="_blank" >6. Zhiqi Li, Wenhai Wang, Hongyang Li, Enze Xie, Chonghao Sima, Tong Lu, Qiao Yu, Jifeng Dai; ‘BEVFormer: Learning Bird’s-Eye-View Representation from Multi-Camera Images via Spatiotemporal Transformers’  <b>ECCV 2022</b>  <body>
            <a href="https://doi.org/10.48550/arXiv.2203.17270" style="color: #0040ff;">[Paper]</a>
          </body>
          <body>
            <a href="https://github.com/fundamentalvision/BEVFormer" style="color: #FF0000;">[Code]</a>
          </body></p>



          <p class="bts" target="_blank" >5. Li Chen, Chonghao Sima, Yang Li, Zehan Zheng, Jiajie Xu, Xiangwei Geng, Hongyang Li, Conghui He, Jianping Shi, Yu Qiao, Junchi Yan; ‘PersFormer: 3D Lane Detection via Perspective Transformer and the OpenLane Benchmark’ <b>ECCV 2022 (Oral) </b>  <body>
            <a href="https://doi.org/10.48550/arXiv.2203.11089" style="color: #0040ff;">[Paper]</a>
          </body>
          <body>
            <a href="https://github.com/OpenPerceptionX/OpenLane" style="color: #FF0000;">[Code]</a>
          </body></p>




          <p class="bts" target="_blank" >4. Shaofeng Zhang, Lyn Qiu, Feng Zhu, Junchi Yan, Hengrui Zhang, Rui Zhao, Hongyang Li, Xiaokang Yang; ‘Align Representations With Base: A New Approach to Self-Supervised Learning’, 2022, pp. 16600–609  <b>CVPR 2022</b><body>
            <a href="https://openaccess.thecvf.com/content/CVPR2022/html/Zhang_Align_Representations_With_Base_A_New_Approach_to_Self-Supervised_Learning_CVPR_2022_paper.html" style="color: #0040ff;">[Paper]</a>
          </body></p>



          <p class="bts" target="_blank" >3. Yunsong Zhou, Yuan He, Hongzi Zhu, Cheng Wang, Hongyang Li, Qinhong Jiang; ‘MonoEF: Extrinsic Parameter Free Monocular 3D Object Detection’, IEEE Transactions on Pattern Analysis and Machine Intelligence, 44.12 (2022), 10114–28   <b>PAMI 2022</b> <body>
            <a href="https://doi.org/10.1109/TPAMI.2021.3136899" style="color: #0040ff;">[Paper]</a>
          </body></p>



          <p class="bts" target="_blank" >2. Yunsong Zhou, Yuan He, Hongzi Zhu, Cheng Wang, Hongyang Li, Qinhong Jiang; ‘Monocular 3D Object Detection: An Extrinsic Parameter Free Approach’, 2021, pp. 7556–66 <b>CVPR 2021</b> <body>
            <a href="https://openaccess.thecvf.com/content/CVPR2021/html/Zhou_Monocular_3D_Object_Detection_An_Extrinsic_Parameter_Free_Approach_CVPR_2021_paper.html" style="color: #0040ff;">[Paper]</a>
          </body></p>




          <p class="bts" target="_blank" >1. Shichao Li, Zengqiang Yan, Hongyang Li, Kwang-Ting Cheng; ‘Exploring Intermediate Representation for Monocular Vehicle Pose Estimation’, 2021, pp. 1873–83  <b>CVPR 2021</b> <body>
            <a href="https://openaccess.thecvf.com/content/CVPR2021/html/Li_Exploring_intermediate_representation_for_monocular_vehicle_pose_estimation_CVPR_2021_paper.html" style="color: #0040ff;">[Paper]</a>
          </body>
          <body>
            <a href="https://github.com/Nicholasli1995/EgoNet" style="color: #FF0000;">[Code]</a>
          </body></p>




        </article>
      </li>
    </ul>
    <!-- ################################################################################################ -->
    <!-- / main body -->
    <div class="clear"></div>
  </main>
</div>

<div class="wrapper row4">
  <footer id="footer" class="hoc clear"> 
    <!-- ################################################################################################ -->
    <div class="center btmspace-50">
      <h6 class="heading">OpenDriveLab</h6>
      <nav>
        <ul class="nospace inline pushright uppercase">
          <li><a href="../index.html"><i class="fas fa-lg fa-home"></i></a></li>
          <li><a href="#">About</a></li>
          <!-- <li><a href="#">Contact</a></li> -->
          <li><a href="#">Terms</a></li>
          <li><a href="#">Privacy</a></li>
          <!-- <li><a href="#">Cookies</a></li> -->
          <li><a href="#">Disclaimer</a></li>
        </ul>
      </nav>
    </div>
    <!-- ################################################################################################ -->
  </footer>
</div>
<!-- ################################################################################################ -->
<!-- ################################################################################################ -->
<!-- ################################################################################################ -->
<div class="wrapper row5">
  <div id="copyright" class="hoc clear"> 
    <!-- ################################################################################################ -->
    <p class="fl_left">Copyright &copy; 2023 - All Rights Reserved - OpenDriveLab</p>
    <p class="fl_right">Template by <a target="_blank" href="https://www.os-templates.com/" title="Free Website Templates">OS Templates</a></p>
    <!-- ################################################################################################ -->
  </div>
</div>
<!-- ################################################################################################ -->
<!-- ################################################################################################ -->
<!-- ################################################################################################ -->
<a id="backtotop" href="#top"><i class="fas fa-chevron-up"></i></a>
<!-- JAVASCRIPTS -->
<script src="../layout/scripts/jquery.min.js"></script>
<script src="../layout/scripts/jquery.backtotop.js"></script>
<script src="../layout/scripts/jquery.mobilemenu.js"></script>
</body>
</html>
